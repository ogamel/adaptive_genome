{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844faf10-c25c-4575-8dc5-a0a27bee6af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "Here we explore training of neural networks that predict the GERP score from the sequence. We try multiple network architectures and report the results of each.\n",
    "\n",
    "\n",
    "Inversion symmetry of score implies local window should extend both sides equally - since if one sequence affects only in one direction, its reverse complement will affect in the opposite direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e3bde-7fce-492d-9ab4-3357fb905ca8",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd48c92b-72e2-4b3f-a791-2e4e28c9ffd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import dill\n",
    "import os\n",
    "import numpy as np\n",
    "from data.load import read_sequence, read_annotation_generator, examine_annotation, read_gerp_scorer\n",
    "from data.paths import chr17_paths # paths to source data files\n",
    "from data.process import get_train_test_x_y\n",
    "\n",
    "# from score_nn_modeling import LocalWindowModel, LocalTransformerEncoderModel, ModelTrainer\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from lightgbm import LGBMRegressor\n",
    "\n",
    "from score_nn_modeling import LocalWindowModel, SymmetricLocalWindowModel, LocalTransformerEncoderModel, ModelTrainer\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1bef3d-9964-40d3-84a2-6399b9f1e022",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 200\n",
    "\n",
    "# display options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45369b2-2b25-4c87-bd62-e17ac9658fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e3754-2530-49cb-8090-8ea1405cb17c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0262bdf-26bb-4de9-981d-ec95f79d1070",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start the analysis with human chromosome 17\n",
    "paths = chr17_paths\n",
    "\n",
    "# get the raw sequence dictionary, from a FASTA file\n",
    "seq_dict = read_sequence(paths.sequence)\n",
    "\n",
    "# # (optional) examine annotations, from the annotation GFF file\n",
    "# examine_annotation(paths.annotation)\n",
    "\n",
    "# get the annotated sequence generator function, from the annotation GFF file\n",
    "seq_records_gen = read_annotation_generator(paths.annotation, seq_dict=seq_dict)\n",
    "\n",
    "# get GERP retrieval function, from the BigWig file\n",
    "gerp_scorer = read_gerp_scorer(paths.gerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029b2722-b194-4240-a17b-8f727cb16f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading saved xy data from ./__state__/xy_data.pkl.\n"
     ]
    }
   ],
   "source": [
    "# One hot encode the sequence in a sliding window\n",
    "# process from scratch, or load dill / pickle file if done before\n",
    "xy_datapath = './__state__/xy_data.pkl'\n",
    "if os.path.isfile(xy_datapath):\n",
    "    logging.info(f'Loading saved xy data from {xy_datapath}.')\n",
    "    with open(xy_datapath, 'rb') as file:\n",
    "        xy_data = dill.load(file)\n",
    "        x_train, y_train, x_test, y_test = xy_data\n",
    "else:\n",
    "    x_train, y_train, x_test, y_test = get_train_test_x_y(seq_records_gen, gerp_scorer, ['CDS'], max_train_rows=2000000)\n",
    "    \n",
    "    logging.info(f'Saving xy data to {xy_datapath}.')\n",
    "    with open(xy_datapath, 'wb') as file:\n",
    "        xy_data = (x_train, y_train, x_test, y_test)\n",
    "        dill.dump(xy_data, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb82a78-5674-430f-85e0-dfc158b0df99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classic ML Regression Models\n",
    "## Model selection\n",
    "Here we train different ML models, and rate them with train and test R^2, which measures the proportion of the variance in the scores we are trying to predict that is explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398985cf-4bc2-471e-99df-0ee19cad4b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor_classes = [XGBRegressor, GradientBoostingRegressor, ElasticNet, SGDRegressor, BayesianRidge, LinearRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fdda9e7-31d2-411d-aa72-05837f07a292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Regressor: XGBRegressor.  Train R^2: 0.126.  Test R^2: 0.118.\n",
      "INFO:root:Regressor: GradientBoostingRegressor.  Train R^2: 0.069.  Test R^2: 0.071.\n",
      "INFO:root:Regressor: ElasticNet.  Train R^2: 0.000.  Test R^2: -0.000.\n",
      "INFO:root:Regressor: SGDRegressor.  Train R^2: 0.051.  Test R^2: 0.053.\n",
      "INFO:root:Regressor: BayesianRidge.  Train R^2: 0.052.  Test R^2: 0.054.\n",
      "INFO:root:Regressor: LinearRegression.  Train R^2: 0.052.  Test R^2: 0.054.\n"
     ]
    }
   ],
   "source": [
    "ml_models = {}\n",
    "for reg_class in regressor_classes:\n",
    "    model = reg_class()\n",
    "    model.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    class_name = reg_class.__name__\n",
    "    train_R2 = model.score(x_train, y_train.ravel())\n",
    "    test_R2 = model.score(x_test, y_test.ravel())\n",
    "    logging.info(f'Regressor: {class_name}.  Train R^2: {train_R2:.3f}.  Test R^2: {test_R2:.3f}.')\n",
    "    \n",
    "    ml_models[class_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60049f1-fa69-4831-874a-1a1ec42875a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Narrowing the dependence\n",
    "Given we conclude XGBRegressor is the best performing, we can use it with different local window size and offsets. We do this by trimming the input features by various values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22529230-1d78-4448-a8b3-0760f45ea83e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start 0, End 0, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.009.\n",
      "INFO:root:Start 0, End 1, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 0, End 2, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.013.  Test R^2: 0.014.\n",
      "INFO:root:Start 0, End 3, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.023.  Test R^2: 0.024.\n",
      "INFO:root:Start 0, End 4, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.026.  Test R^2: 0.026.\n",
      "INFO:root:Start 0, End 5, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.031.  Test R^2: 0.029.\n",
      "INFO:root:Start 0, End 6, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.040.  Test R^2: 0.039.\n",
      "INFO:root:Start 0, End 7, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.044.  Test R^2: 0.042.\n",
      "INFO:root:Start 0, End 8, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.058.  Test R^2: 0.054.\n",
      "INFO:root:Start 0, End 9, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.072.  Test R^2: 0.068.\n",
      "INFO:root:Start 0, End 10, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.089.  Test R^2: 0.084.\n",
      "INFO:root:Start 0, End 11, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.096.  Test R^2: 0.090.\n",
      "INFO:root:Start 0, End 12, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.104.  Test R^2: 0.099.\n",
      "INFO:root:Start 0, End 13, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.107.  Test R^2: 0.101.\n",
      "INFO:root:Start 0, End 14, x_train_sub.shape (1525923, 60)\n",
      "INFO:root:\tTrain R^2: 0.110.  Test R^2: 0.104.\n",
      "INFO:root:Start 0, End 15, x_train_sub.shape (1525923, 64)\n",
      "INFO:root:\tTrain R^2: 0.116.  Test R^2: 0.110.\n",
      "INFO:root:Start 0, End 16, x_train_sub.shape (1525923, 68)\n",
      "INFO:root:\tTrain R^2: 0.118.  Test R^2: 0.111.\n",
      "INFO:root:Start 0, End 17, x_train_sub.shape (1525923, 72)\n",
      "INFO:root:\tTrain R^2: 0.121.  Test R^2: 0.113.\n",
      "INFO:root:Start 0, End 18, x_train_sub.shape (1525923, 76)\n",
      "INFO:root:\tTrain R^2: 0.126.  Test R^2: 0.118.\n",
      "INFO:root:Start 1, End 1, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 1, End 2, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.003.  Test R^2: 0.003.\n",
      "INFO:root:Start 1, End 3, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.014.\n",
      "INFO:root:Start 1, End 4, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.016.  Test R^2: 0.017.\n",
      "INFO:root:Start 1, End 5, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.021.  Test R^2: 0.020.\n",
      "INFO:root:Start 1, End 6, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.032.  Test R^2: 0.030.\n",
      "INFO:root:Start 1, End 7, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.036.  Test R^2: 0.034.\n",
      "INFO:root:Start 1, End 8, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.050.  Test R^2: 0.046.\n",
      "INFO:root:Start 1, End 9, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.064.  Test R^2: 0.060.\n",
      "INFO:root:Start 1, End 10, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.081.  Test R^2: 0.076.\n",
      "INFO:root:Start 1, End 11, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.089.  Test R^2: 0.083.\n",
      "INFO:root:Start 1, End 12, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.098.  Test R^2: 0.092.\n",
      "INFO:root:Start 1, End 13, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.101.  Test R^2: 0.095.\n",
      "INFO:root:Start 1, End 14, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.104.  Test R^2: 0.098.\n",
      "INFO:root:Start 1, End 15, x_train_sub.shape (1525923, 60)\n",
      "INFO:root:\tTrain R^2: 0.111.  Test R^2: 0.104.\n",
      "INFO:root:Start 1, End 16, x_train_sub.shape (1525923, 64)\n",
      "INFO:root:\tTrain R^2: 0.112.  Test R^2: 0.106.\n",
      "INFO:root:Start 1, End 17, x_train_sub.shape (1525923, 68)\n",
      "INFO:root:\tTrain R^2: 0.116.  Test R^2: 0.108.\n",
      "INFO:root:Start 1, End 18, x_train_sub.shape (1525923, 72)\n",
      "INFO:root:\tTrain R^2: 0.121.  Test R^2: 0.113.\n",
      "INFO:root:Start 2, End 2, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 2, End 3, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 2, End 4, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.012.  Test R^2: 0.013.\n",
      "INFO:root:Start 2, End 5, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.016.  Test R^2: 0.016.\n",
      "INFO:root:Start 2, End 6, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.027.  Test R^2: 0.027.\n",
      "INFO:root:Start 2, End 7, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.031.  Test R^2: 0.030.\n",
      "INFO:root:Start 2, End 8, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.045.  Test R^2: 0.042.\n",
      "INFO:root:Start 2, End 9, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.059.  Test R^2: 0.056.\n",
      "INFO:root:Start 2, End 10, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.076.  Test R^2: 0.072.\n",
      "INFO:root:Start 2, End 11, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.085.  Test R^2: 0.079.\n",
      "INFO:root:Start 2, End 12, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.094.  Test R^2: 0.089.\n",
      "INFO:root:Start 2, End 13, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.097.  Test R^2: 0.092.\n",
      "INFO:root:Start 2, End 14, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.101.  Test R^2: 0.095.\n",
      "INFO:root:Start 2, End 15, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.108.  Test R^2: 0.102.\n",
      "INFO:root:Start 2, End 16, x_train_sub.shape (1525923, 60)\n",
      "INFO:root:\tTrain R^2: 0.109.  Test R^2: 0.103.\n",
      "INFO:root:Start 2, End 17, x_train_sub.shape (1525923, 64)\n",
      "INFO:root:\tTrain R^2: 0.113.  Test R^2: 0.105.\n",
      "INFO:root:Start 2, End 18, x_train_sub.shape (1525923, 68)\n",
      "INFO:root:\tTrain R^2: 0.118.  Test R^2: 0.111.\n",
      "INFO:root:Start 3, End 3, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.009.\n",
      "INFO:root:Start 3, End 4, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 3, End 5, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.014.\n",
      "INFO:root:Start 3, End 6, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.024.  Test R^2: 0.024.\n",
      "INFO:root:Start 3, End 7, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.027.  Test R^2: 0.027.\n",
      "INFO:root:Start 3, End 8, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.041.  Test R^2: 0.040.\n",
      "INFO:root:Start 3, End 9, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.055.  Test R^2: 0.053.\n",
      "INFO:root:Start 3, End 10, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.073.  Test R^2: 0.069.\n",
      "INFO:root:Start 3, End 11, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.081.  Test R^2: 0.077.\n",
      "INFO:root:Start 3, End 12, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.091.  Test R^2: 0.087.\n",
      "INFO:root:Start 3, End 13, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.094.  Test R^2: 0.089.\n",
      "INFO:root:Start 3, End 14, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.099.  Test R^2: 0.093.\n",
      "INFO:root:Start 3, End 15, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.105.  Test R^2: 0.100.\n",
      "INFO:root:Start 3, End 16, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.108.  Test R^2: 0.101.\n",
      "INFO:root:Start 3, End 17, x_train_sub.shape (1525923, 60)\n",
      "INFO:root:\tTrain R^2: 0.111.  Test R^2: 0.104.\n",
      "INFO:root:Start 3, End 18, x_train_sub.shape (1525923, 64)\n",
      "INFO:root:\tTrain R^2: 0.116.  Test R^2: 0.109.\n",
      "INFO:root:Start 4, End 4, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 4, End 5, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.004.  Test R^2: 0.003.\n",
      "INFO:root:Start 4, End 6, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.015.\n",
      "INFO:root:Start 4, End 7, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.017.  Test R^2: 0.018.\n",
      "INFO:root:Start 4, End 8, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.030.  Test R^2: 0.029.\n",
      "INFO:root:Start 4, End 9, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.044.  Test R^2: 0.043.\n",
      "INFO:root:Start 4, End 10, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.062.  Test R^2: 0.059.\n",
      "INFO:root:Start 4, End 11, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.071.  Test R^2: 0.067.\n",
      "INFO:root:Start 4, End 12, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.082.  Test R^2: 0.079.\n",
      "INFO:root:Start 4, End 13, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.086.  Test R^2: 0.082.\n",
      "INFO:root:Start 4, End 14, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.091.  Test R^2: 0.086.\n",
      "INFO:root:Start 4, End 15, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.099.  Test R^2: 0.094.\n",
      "INFO:root:Start 4, End 16, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.101.  Test R^2: 0.095.\n",
      "INFO:root:Start 4, End 17, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.104.  Test R^2: 0.098.\n",
      "INFO:root:Start 4, End 18, x_train_sub.shape (1525923, 60)\n",
      "INFO:root:\tTrain R^2: 0.111.  Test R^2: 0.104.\n",
      "INFO:root:Start 5, End 5, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 5, End 6, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 5, End 7, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.013.  Test R^2: 0.014.\n",
      "INFO:root:Start 5, End 8, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.025.  Test R^2: 0.025.\n",
      "INFO:root:Start 5, End 9, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.038.  Test R^2: 0.039.\n",
      "INFO:root:Start 5, End 10, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.055.  Test R^2: 0.054.\n",
      "INFO:root:Start 5, End 11, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.065.  Test R^2: 0.062.\n",
      "INFO:root:Start 5, End 12, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.078.  Test R^2: 0.075.\n",
      "INFO:root:Start 5, End 13, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.082.  Test R^2: 0.078.\n",
      "INFO:root:Start 5, End 14, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.087.  Test R^2: 0.082.\n",
      "INFO:root:Start 5, End 15, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.095.  Test R^2: 0.091.\n",
      "INFO:root:Start 5, End 16, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.097.  Test R^2: 0.092.\n",
      "INFO:root:Start 5, End 17, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.101.  Test R^2: 0.095.\n",
      "INFO:root:Start 5, End 18, x_train_sub.shape (1525923, 56)\n",
      "INFO:root:\tTrain R^2: 0.107.  Test R^2: 0.101.\n",
      "INFO:root:Start 6, End 6, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.009.\n",
      "INFO:root:Start 6, End 7, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 6, End 8, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.021.  Test R^2: 0.022.\n",
      "INFO:root:Start 6, End 9, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.033.  Test R^2: 0.034.\n",
      "INFO:root:Start 6, End 10, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.050.  Test R^2: 0.050.\n",
      "INFO:root:Start 6, End 11, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.060.  Test R^2: 0.058.\n",
      "INFO:root:Start 6, End 12, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.073.  Test R^2: 0.071.\n",
      "INFO:root:Start 6, End 13, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.077.  Test R^2: 0.075.\n",
      "INFO:root:Start 6, End 14, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.083.  Test R^2: 0.079.\n",
      "INFO:root:Start 6, End 15, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.092.  Test R^2: 0.088.\n",
      "INFO:root:Start 6, End 16, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.094.  Test R^2: 0.089.\n",
      "INFO:root:Start 6, End 17, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.098.  Test R^2: 0.092.\n",
      "INFO:root:Start 6, End 18, x_train_sub.shape (1525923, 52)\n",
      "INFO:root:\tTrain R^2: 0.104.  Test R^2: 0.099.\n",
      "INFO:root:Start 7, End 7, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.000.  Test R^2: 0.000.\n",
      "INFO:root:Start 7, End 8, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.009.  Test R^2: 0.009.\n",
      "INFO:root:Start 7, End 9, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.020.  Test R^2: 0.021.\n",
      "INFO:root:Start 7, End 10, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.035.  Test R^2: 0.036.\n",
      "INFO:root:Start 7, End 11, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.045.  Test R^2: 0.044.\n",
      "INFO:root:Start 7, End 12, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.060.  Test R^2: 0.059.\n",
      "INFO:root:Start 7, End 13, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.065.  Test R^2: 0.063.\n",
      "INFO:root:Start 7, End 14, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.072.  Test R^2: 0.068.\n",
      "INFO:root:Start 7, End 15, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.082.  Test R^2: 0.078.\n",
      "INFO:root:Start 7, End 16, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.085.  Test R^2: 0.080.\n",
      "INFO:root:Start 7, End 17, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.089.  Test R^2: 0.084.\n",
      "INFO:root:Start 7, End 18, x_train_sub.shape (1525923, 48)\n",
      "INFO:root:\tTrain R^2: 0.096.  Test R^2: 0.091.\n",
      "INFO:root:Start 8, End 8, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.006.  Test R^2: 0.005.\n",
      "INFO:root:Start 8, End 9, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.014.\n",
      "INFO:root:Start 8, End 10, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.027.  Test R^2: 0.027.\n",
      "INFO:root:Start 8, End 11, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.036.  Test R^2: 0.036.\n",
      "INFO:root:Start 8, End 12, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.051.  Test R^2: 0.051.\n",
      "INFO:root:Start 8, End 13, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.056.  Test R^2: 0.055.\n",
      "INFO:root:Start 8, End 14, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.063.  Test R^2: 0.060.\n",
      "INFO:root:Start 8, End 15, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.074.  Test R^2: 0.071.\n",
      "INFO:root:Start 8, End 16, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.077.  Test R^2: 0.073.\n",
      "INFO:root:Start 8, End 17, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.082.  Test R^2: 0.077.\n",
      "INFO:root:Start 8, End 18, x_train_sub.shape (1525923, 44)\n",
      "INFO:root:\tTrain R^2: 0.090.  Test R^2: 0.084.\n",
      "INFO:root:Start 9, End 9, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.000.  Test R^2: 0.000.\n",
      "INFO:root:Start 9, End 10, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.012.  Test R^2: 0.013.\n",
      "INFO:root:Start 9, End 11, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.019.  Test R^2: 0.020.\n",
      "INFO:root:Start 9, End 12, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.033.  Test R^2: 0.034.\n",
      "INFO:root:Start 9, End 13, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.037.  Test R^2: 0.038.\n",
      "INFO:root:Start 9, End 14, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.044.  Test R^2: 0.043.\n",
      "INFO:root:Start 9, End 15, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.055.  Test R^2: 0.053.\n",
      "INFO:root:Start 9, End 16, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.059.  Test R^2: 0.056.\n",
      "INFO:root:Start 9, End 17, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.064.  Test R^2: 0.059.\n",
      "INFO:root:Start 9, End 18, x_train_sub.shape (1525923, 40)\n",
      "INFO:root:\tTrain R^2: 0.072.  Test R^2: 0.067.\n",
      "INFO:root:Start 10, End 10, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.005.  Test R^2: 0.005.\n",
      "INFO:root:Start 10, End 11, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.009.  Test R^2: 0.008.\n",
      "INFO:root:Start 10, End 12, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.021.  Test R^2: 0.022.\n",
      "INFO:root:Start 10, End 13, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.024.  Test R^2: 0.025.\n",
      "INFO:root:Start 10, End 14, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.030.  Test R^2: 0.030.\n",
      "INFO:root:Start 10, End 15, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.041.  Test R^2: 0.040.\n",
      "INFO:root:Start 10, End 16, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.045.  Test R^2: 0.042.\n",
      "INFO:root:Start 10, End 17, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.050.  Test R^2: 0.046.\n",
      "INFO:root:Start 10, End 18, x_train_sub.shape (1525923, 36)\n",
      "INFO:root:\tTrain R^2: 0.058.  Test R^2: 0.054.\n",
      "INFO:root:Start 11, End 11, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 11, End 12, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.011.  Test R^2: 0.012.\n",
      "INFO:root:Start 11, End 13, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.013.  Test R^2: 0.014.\n",
      "INFO:root:Start 11, End 14, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.018.  Test R^2: 0.018.\n",
      "INFO:root:Start 11, End 15, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.028.  Test R^2: 0.028.\n",
      "INFO:root:Start 11, End 16, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.032.  Test R^2: 0.030.\n",
      "INFO:root:Start 11, End 17, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.037.  Test R^2: 0.034.\n",
      "INFO:root:Start 11, End 18, x_train_sub.shape (1525923, 32)\n",
      "INFO:root:\tTrain R^2: 0.045.  Test R^2: 0.041.\n",
      "INFO:root:Start 12, End 12, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.009.\n",
      "INFO:root:Start 12, End 13, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.011.\n",
      "INFO:root:Start 12, End 14, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.015.\n",
      "INFO:root:Start 12, End 15, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.024.  Test R^2: 0.025.\n",
      "INFO:root:Start 12, End 16, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.027.  Test R^2: 0.027.\n",
      "INFO:root:Start 12, End 17, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.032.  Test R^2: 0.030.\n",
      "INFO:root:Start 12, End 18, x_train_sub.shape (1525923, 28)\n",
      "INFO:root:\tTrain R^2: 0.040.  Test R^2: 0.038.\n",
      "INFO:root:Start 13, End 13, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 13, End 14, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.004.  Test R^2: 0.003.\n",
      "INFO:root:Start 13, End 15, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.014.\n",
      "INFO:root:Start 13, End 16, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.016.  Test R^2: 0.016.\n",
      "INFO:root:Start 13, End 17, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.021.  Test R^2: 0.020.\n",
      "INFO:root:Start 13, End 18, x_train_sub.shape (1525923, 24)\n",
      "INFO:root:\tTrain R^2: 0.031.  Test R^2: 0.029.\n",
      "INFO:root:Start 14, End 14, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 14, End 15, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.011.  Test R^2: 0.011.\n",
      "INFO:root:Start 14, End 16, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.013.  Test R^2: 0.013.\n",
      "INFO:root:Start 14, End 17, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.017.  Test R^2: 0.017.\n",
      "INFO:root:Start 14, End 18, x_train_sub.shape (1525923, 20)\n",
      "INFO:root:\tTrain R^2: 0.026.  Test R^2: 0.026.\n",
      "INFO:root:Start 15, End 15, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.009.\n",
      "INFO:root:Start 15, End 16, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.010.\n",
      "INFO:root:Start 15, End 17, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.014.  Test R^2: 0.014.\n",
      "INFO:root:Start 15, End 18, x_train_sub.shape (1525923, 16)\n",
      "INFO:root:\tTrain R^2: 0.023.  Test R^2: 0.023.\n",
      "INFO:root:Start 16, End 16, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 16, End 17, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.004.  Test R^2: 0.003.\n",
      "INFO:root:Start 16, End 18, x_train_sub.shape (1525923, 12)\n",
      "INFO:root:\tTrain R^2: 0.013.  Test R^2: 0.014.\n",
      "INFO:root:Start 17, End 17, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.001.  Test R^2: 0.001.\n",
      "INFO:root:Start 17, End 18, x_train_sub.shape (1525923, 8)\n",
      "INFO:root:\tTrain R^2: 0.010.  Test R^2: 0.010.\n",
      "INFO:root:Start 18, End 18, x_train_sub.shape (1525923, 4)\n",
      "INFO:root:\tTrain R^2: 0.008.  Test R^2: 0.008.\n"
     ]
    }
   ],
   "source": [
    "nbases = 4\n",
    "width = x_train.shape[1]//nbases\n",
    "train_R2_all, test_R2_all = np.zeros((width, width)), np.zeros((width, width))\n",
    "for start in range(width):\n",
    "    for end in range(start, width):\n",
    "        \n",
    "        x_train_sub = x_train[:,start*nbases:(end+1)*nbases]\n",
    "        x_test_sub = x_test[:,start*nbases:(end+1)*nbases]\n",
    "        \n",
    "        logging.info(f'Start {start}, End {end}, x_train_sub.shape {x_train_sub.shape}')\n",
    "        \n",
    "        model = XGBRegressor()\n",
    "        model.fit(x_train_sub, y_train.ravel())\n",
    "        \n",
    "        train_R2 = model.score(x_train_sub, y_train.ravel())\n",
    "        test_R2 = model.score(x_test_sub, y_test.ravel())\n",
    "        \n",
    "        train_R2_all[start, end] = train_R2\n",
    "        test_R2_all[start, end] = test_R2\n",
    "        \n",
    "        logging.info(f'\\tTrain R^2: {train_R2:.3f}.  Test R^2: {test_R2:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdab9ba7-00ae-4004-8699-037fac24bc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.795  0.967  1.291  2.262  2.589  3.075  4.032  4.424  5.831  7.24\n",
      "   8.905  9.645 10.408 10.689 11.013 11.639 11.779 12.099 12.553]\n",
      " [ 0.     0.091  0.328  1.351  1.615  2.079  3.167  3.586  4.997  6.411\n",
      "   8.075  8.874  9.791 10.073 10.427 11.073 11.232 11.563 12.092]\n",
      " [ 0.     0.     0.052  0.98   1.208  1.605  2.685  3.101  4.518  5.932\n",
      "   7.612  8.461  9.416  9.69  10.111 10.791 10.946 11.258 11.823]\n",
      " [ 0.     0.     0.     0.812  0.998  1.357  2.369  2.724  4.134  5.543\n",
      "   7.251  8.144  9.119  9.436  9.856 10.542 10.77  11.093 11.626]\n",
      " [ 0.     0.     0.     0.     0.088  0.352  1.415  1.713  3.022  4.439\n",
      "   6.167  7.123  8.245  8.604  9.08   9.871 10.085 10.447 11.054]\n",
      " [ 0.     0.     0.     0.     0.     0.069  1.038  1.292  2.499  3.828\n",
      "   5.547  6.525  7.756  8.165  8.663  9.508  9.725 10.083 10.703]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.819  1.005  2.144  3.331\n",
      "   4.97   5.985  7.289  7.724  8.285  9.159  9.421  9.786 10.413]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.029  0.883  2.002\n",
      "   3.511  4.522  6.003  6.516  7.151  8.157  8.455  8.907  9.616]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.586  1.351\n",
      "   2.696  3.581  5.055  5.611  6.281  7.377  7.712  8.187  8.952]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.013\n",
      "   1.243  1.949  3.27   3.747  4.402  5.514  5.868  6.377  7.184]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.524  0.885  2.131  2.447  3.008  4.137  4.484  5.013  5.814]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.082  1.083  1.321  1.786  2.831  3.176  3.717  4.506]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.834  1.013  1.421  2.397  2.684  3.22   4.049]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.054  0.354  1.394  1.619  2.138  3.087]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.106  1.06   1.258  1.714  2.637]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.837  0.985  1.394  2.257]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.052  0.361  1.283]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.127  0.97 ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.761]]\n",
      "[[ 0.902  1.084  1.401  2.414  2.635  2.947  3.857  4.164  5.422  6.792\n",
      "   8.37   9.046  9.863 10.109 10.368 10.996 11.104 11.314 11.767]\n",
      " [ 0.     0.096  0.329  1.439  1.66   2.001  3.049  3.363  4.599  5.978\n",
      "   7.552  8.285  9.245  9.479  9.786 10.395 10.566 10.786 11.277]\n",
      " [ 0.     0.     0.053  1.079  1.29   1.621  2.685  2.984  4.205  5.562\n",
      "   7.179  7.887  8.907  9.185  9.469 10.167 10.267 10.522 11.07 ]\n",
      " [ 0.     0.     0.     0.881  1.056  1.38   2.444  2.747  3.959  5.306\n",
      "   6.882  7.656  8.684  8.948  9.294  9.968 10.148 10.416 10.905]\n",
      " [ 0.     0.     0.     0.     0.087  0.331  1.486  1.781  2.94   4.289\n",
      "   5.882  6.694  7.86   8.161  8.572  9.359  9.526  9.767 10.425]\n",
      " [ 0.     0.     0.     0.     0.     0.061  1.129  1.407  2.542  3.873\n",
      "   5.446  6.227  7.495  7.81   8.25   9.062  9.183  9.486 10.099]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.909  1.123  2.2    3.44\n",
      "   5.005  5.826  7.101  7.467  7.917  8.783  8.925  9.233  9.887]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.04   0.851  2.084\n",
      "   3.561  4.425  5.894  6.319  6.806  7.823  8.026  8.375  9.127]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.541  1.392\n",
      "   2.727  3.554  5.077  5.508  6.036  7.095  7.342  7.712  8.446]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.038\n",
      "   1.288  1.967  3.365  3.769  4.282  5.33   5.564  5.935  6.72 ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.505  0.843  2.212  2.504  2.975  4.023  4.246  4.641  5.389]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.079  1.188  1.417  1.835  2.831  3.033  3.412  4.131]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.923  1.101  1.486  2.482  2.671  3.022  3.78 ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.056  0.349  1.44   1.614  2.003  2.875]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.107  1.129  1.303  1.682  2.592]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.9    1.045  1.408  2.321]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.059  0.345  1.357]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.098  1.035]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.846]]\n"
     ]
    }
   ],
   "source": [
    "print(100*np.round(train_R2_all, 5))\n",
    "print(100*np.round(test_R2_all,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83c565-f51f-491d-8e29-5ba8bb231900",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network Models\n",
    "Here we train different neural network architectures, and rate them with the mean square error loss as well as R^2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d3f1d-3992-4ee6-ba32-e0a7a930f448",
   "metadata": {},
   "source": [
    "## Local Window Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "241ffd5e-e11b-47e9-9fa2-8462fe124ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = LocalWindowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b097e90-c861-4bdb-9371-8b1e7b441896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_trainer1 = ModelTrainer(model1, epochs=20000, optimizer=optax.sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd9b78b-ecea-4906-9647-8632c0935bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 7.3023. R^2: -0.0302.\n",
      "INFO:root:Epoch 100. Training loss: 6.9039. R^2: 0.0260.\n",
      "INFO:root:Epoch 200. Training loss: 6.6829. R^2: 0.0571.\n",
      "INFO:root:Epoch 300. Training loss: 6.6343. R^2: 0.0640.\n",
      "INFO:root:Epoch 400. Training loss: 6.6011. R^2: 0.0687.\n",
      "INFO:root:Epoch 500. Training loss: 6.5675. R^2: 0.0734.\n",
      "INFO:root:Epoch 600. Training loss: 6.5299. R^2: 0.0787.\n",
      "INFO:root:Epoch 700. Training loss: 6.4990. R^2: 0.0831.\n",
      "INFO:root:Epoch 800. Training loss: 6.4764. R^2: 0.0863.\n",
      "INFO:root:Epoch 900. Training loss: 6.4587. R^2: 0.0888.\n",
      "INFO:root:Epoch 1,000. Training loss: 6.4449. R^2: 0.0907.\n",
      "INFO:root:Epoch 1,100. Training loss: 6.4333. R^2: 0.0924.\n",
      "INFO:root:Epoch 1,200. Training loss: 6.4233. R^2: 0.0938.\n",
      "INFO:root:Epoch 1,300. Training loss: 6.4143. R^2: 0.0950.\n",
      "INFO:root:Epoch 1,400. Training loss: 6.4065. R^2: 0.0961.\n",
      "INFO:root:Epoch 1,500. Training loss: 6.3992. R^2: 0.0972.\n",
      "INFO:root:Epoch 1,600. Training loss: 6.3931. R^2: 0.0980.\n",
      "INFO:root:Epoch 1,700. Training loss: 6.3872. R^2: 0.0989.\n",
      "INFO:root:Epoch 1,800. Training loss: 6.3824. R^2: 0.0995.\n",
      "INFO:root:Epoch 1,900. Training loss: 6.3775. R^2: 0.1002.\n",
      "INFO:root:Epoch 2,000. Training loss: 6.3735. R^2: 0.1008.\n",
      "INFO:root:Epoch 2,100. Training loss: 6.3692. R^2: 0.1014.\n",
      "INFO:root:Epoch 2,200. Training loss: 6.3653. R^2: 0.1019.\n",
      "INFO:root:Epoch 2,300. Training loss: 6.3622. R^2: 0.1024.\n",
      "INFO:root:Epoch 2,400. Training loss: 6.3586. R^2: 0.1029.\n",
      "INFO:root:Epoch 2,500. Training loss: 6.3552. R^2: 0.1034.\n",
      "INFO:root:Epoch 2,600. Training loss: 6.3523. R^2: 0.1038.\n",
      "INFO:root:Epoch 2,700. Training loss: 6.3492. R^2: 0.1042.\n",
      "INFO:root:Epoch 2,800. Training loss: 6.3461. R^2: 0.1047.\n",
      "INFO:root:Epoch 2,900. Training loss: 6.3438. R^2: 0.1050.\n",
      "INFO:root:Epoch 3,000. Training loss: 6.3410. R^2: 0.1054.\n",
      "INFO:root:Epoch 3,100. Training loss: 6.3383. R^2: 0.1058.\n",
      "INFO:root:Epoch 3,200. Training loss: 6.3363. R^2: 0.1060.\n",
      "INFO:root:Epoch 3,300. Training loss: 6.3341. R^2: 0.1064.\n",
      "INFO:root:Epoch 3,400. Training loss: 6.3324. R^2: 0.1066.\n",
      "INFO:root:Epoch 3,500. Training loss: 6.3307. R^2: 0.1068.\n",
      "INFO:root:Epoch 3,600. Training loss: 6.3282. R^2: 0.1072.\n",
      "INFO:root:Epoch 3,700. Training loss: 6.3270. R^2: 0.1074.\n",
      "INFO:root:Epoch 3,800. Training loss: 6.3243. R^2: 0.1077.\n",
      "INFO:root:Epoch 3,900. Training loss: 6.3231. R^2: 0.1079.\n",
      "INFO:root:Epoch 4,000. Training loss: 6.3221. R^2: 0.1081.\n",
      "INFO:root:Epoch 4,100. Training loss: 6.3193. R^2: 0.1084.\n",
      "INFO:root:Epoch 4,200. Training loss: 6.3190. R^2: 0.1085.\n",
      "INFO:root:Epoch 4,300. Training loss: 6.3186. R^2: 0.1085.\n",
      "INFO:root:Epoch 4,400. Training loss: 6.3162. R^2: 0.1089.\n",
      "INFO:root:Epoch 4,500. Training loss: 6.3139. R^2: 0.1092.\n",
      "INFO:root:Epoch 4,600. Training loss: 6.3128. R^2: 0.1094.\n",
      "INFO:root:Epoch 4,700. Training loss: 6.3112. R^2: 0.1096.\n",
      "INFO:root:Epoch 4,800. Training loss: 6.3105. R^2: 0.1097.\n",
      "INFO:root:Epoch 4,900. Training loss: 6.3095. R^2: 0.1098.\n",
      "INFO:root:Epoch 5,000. Training loss: 6.3090. R^2: 0.1099.\n",
      "INFO:root:Epoch 5,100. Training loss: 6.3079. R^2: 0.1100.\n",
      "INFO:root:Epoch 5,200. Training loss: 6.3079. R^2: 0.1100.\n",
      "INFO:root:Epoch 5,300. Training loss: 6.3075. R^2: 0.1101.\n",
      "INFO:root:Epoch 5,400. Training loss: 6.3044. R^2: 0.1105.\n",
      "INFO:root:Epoch 5,500. Training loss: 6.3029. R^2: 0.1108.\n",
      "INFO:root:Epoch 5,600. Training loss: 6.3034. R^2: 0.1107.\n",
      "INFO:root:Epoch 5,700. Training loss: 6.3032. R^2: 0.1107.\n",
      "INFO:root:Epoch 5,800. Training loss: 6.3031. R^2: 0.1107.\n",
      "INFO:root:Epoch 5,900. Training loss: 6.2997. R^2: 0.1112.\n",
      "INFO:root:Epoch 6,000. Training loss: 6.2986. R^2: 0.1114.\n",
      "INFO:root:Epoch 6,100. Training loss: 6.2995. R^2: 0.1112.\n",
      "INFO:root:Epoch 6,200. Training loss: 6.2996. R^2: 0.1112.\n",
      "INFO:root:Epoch 6,300. Training loss: 6.2964. R^2: 0.1117.\n",
      "INFO:root:Epoch 6,400. Training loss: 6.2974. R^2: 0.1115.\n",
      "INFO:root:Epoch 6,500. Training loss: 6.2978. R^2: 0.1115.\n",
      "INFO:root:Epoch 6,600. Training loss: 6.2946. R^2: 0.1119.\n",
      "INFO:root:Epoch 6,700. Training loss: 6.2955. R^2: 0.1118.\n",
      "INFO:root:Epoch 6,800. Training loss: 6.2955. R^2: 0.1118.\n",
      "INFO:root:Epoch 6,900. Training loss: 6.2927. R^2: 0.1122.\n",
      "INFO:root:Epoch 7,000. Training loss: 6.2960. R^2: 0.1117.\n",
      "INFO:root:Epoch 7,100. Training loss: 6.2908. R^2: 0.1125.\n",
      "INFO:root:Epoch 7,200. Training loss: 6.2942. R^2: 0.1120.\n",
      "INFO:root:Epoch 7,300. Training loss: 6.2898. R^2: 0.1126.\n",
      "INFO:root:Epoch 7,400. Training loss: 6.2929. R^2: 0.1122.\n",
      "INFO:root:Epoch 7,500. Training loss: 6.2893. R^2: 0.1127.\n",
      "INFO:root:Epoch 7,600. Training loss: 6.2915. R^2: 0.1124.\n",
      "INFO:root:Epoch 7,700. Training loss: 6.2883. R^2: 0.1128.\n",
      "INFO:root:Epoch 7,800. Training loss: 6.2894. R^2: 0.1127.\n",
      "INFO:root:Epoch 7,900. Training loss: 6.2879. R^2: 0.1129.\n",
      "INFO:root:Epoch 8,000. Training loss: 6.2881. R^2: 0.1128.\n",
      "INFO:root:Epoch 8,100. Training loss: 6.2875. R^2: 0.1129.\n",
      "INFO:root:Epoch 8,200. Training loss: 6.2877. R^2: 0.1129.\n",
      "INFO:root:Epoch 8,300. Training loss: 6.2851. R^2: 0.1133.\n",
      "INFO:root:Epoch 8,400. Training loss: 6.2884. R^2: 0.1128.\n",
      "INFO:root:Epoch 8,500. Training loss: 6.2837. R^2: 0.1135.\n",
      "INFO:root:Epoch 8,600. Training loss: 6.2874. R^2: 0.1129.\n",
      "INFO:root:Epoch 8,700. Training loss: 6.2825. R^2: 0.1136.\n",
      "INFO:root:Epoch 8,800. Training loss: 6.2866. R^2: 0.1131.\n",
      "INFO:root:Epoch 8,900. Training loss: 6.2825. R^2: 0.1136.\n",
      "INFO:root:Epoch 9,000. Training loss: 6.2829. R^2: 0.1136.\n",
      "INFO:root:Epoch 9,100. Training loss: 6.2850. R^2: 0.1133.\n",
      "INFO:root:Epoch 9,200. Training loss: 6.2807. R^2: 0.1139.\n",
      "INFO:root:Epoch 9,300. Training loss: 6.2822. R^2: 0.1137.\n",
      "INFO:root:Epoch 9,400. Training loss: 6.2828. R^2: 0.1136.\n",
      "INFO:root:Epoch 9,500. Training loss: 6.2788. R^2: 0.1142.\n",
      "INFO:root:Epoch 9,600. Training loss: 6.2820. R^2: 0.1137.\n",
      "INFO:root:Epoch 9,700. Training loss: 6.2813. R^2: 0.1138.\n",
      "INFO:root:Epoch 9,800. Training loss: 6.2775. R^2: 0.1143.\n",
      "INFO:root:Epoch 9,900. Training loss: 6.2813. R^2: 0.1138.\n",
      "INFO:root:Epoch 10,000. Training loss: 6.2801. R^2: 0.1140.\n",
      "INFO:root:Epoch 10,100. Training loss: 6.2766. R^2: 0.1145.\n",
      "INFO:root:Epoch 10,200. Training loss: 6.2781. R^2: 0.1143.\n",
      "INFO:root:Epoch 10,300. Training loss: 6.2807. R^2: 0.1139.\n",
      "INFO:root:Epoch 10,400. Training loss: 6.2775. R^2: 0.1143.\n",
      "INFO:root:Epoch 10,500. Training loss: 6.2753. R^2: 0.1147.\n",
      "INFO:root:Epoch 10,600. Training loss: 6.2742. R^2: 0.1148.\n",
      "INFO:root:Epoch 10,700. Training loss: 6.2779. R^2: 0.1143.\n",
      "INFO:root:Epoch 10,800. Training loss: 6.2780. R^2: 0.1143.\n",
      "INFO:root:Epoch 10,900. Training loss: 6.2738. R^2: 0.1149.\n",
      "INFO:root:Epoch 11,000. Training loss: 6.2744. R^2: 0.1148.\n",
      "INFO:root:Epoch 11,100. Training loss: 6.2775. R^2: 0.1143.\n",
      "INFO:root:Epoch 11,200. Training loss: 6.2735. R^2: 0.1149.\n",
      "INFO:root:Epoch 11,300. Training loss: 6.2747. R^2: 0.1147.\n",
      "INFO:root:Epoch 11,400. Training loss: 6.2760. R^2: 0.1145.\n",
      "INFO:root:Epoch 11,500. Training loss: 6.2720. R^2: 0.1151.\n",
      "INFO:root:Epoch 11,600. Training loss: 6.2741. R^2: 0.1148.\n",
      "INFO:root:Epoch 11,700. Training loss: 6.2756. R^2: 0.1146.\n",
      "INFO:root:Epoch 11,800. Training loss: 6.2719. R^2: 0.1151.\n",
      "INFO:root:Epoch 11,900. Training loss: 6.2701. R^2: 0.1154.\n",
      "INFO:root:Epoch 12,000. Training loss: 6.2732. R^2: 0.1149.\n",
      "INFO:root:Epoch 12,100. Training loss: 6.2747. R^2: 0.1147.\n",
      "INFO:root:Epoch 12,200. Training loss: 6.2706. R^2: 0.1153.\n",
      "INFO:root:Epoch 12,300. Training loss: 6.2684. R^2: 0.1156.\n",
      "INFO:root:Epoch 12,400. Training loss: 6.2706. R^2: 0.1153.\n",
      "INFO:root:Epoch 12,500. Training loss: 6.2737. R^2: 0.1149.\n",
      "INFO:root:Epoch 12,600. Training loss: 6.2690. R^2: 0.1155.\n",
      "INFO:root:Epoch 12,700. Training loss: 6.2690. R^2: 0.1155.\n",
      "INFO:root:Epoch 12,800. Training loss: 6.2731. R^2: 0.1150.\n",
      "INFO:root:Epoch 12,900. Training loss: 6.2705. R^2: 0.1153.\n",
      "INFO:root:Epoch 13,000. Training loss: 6.2672. R^2: 0.1158.\n",
      "INFO:root:Epoch 13,100. Training loss: 6.2656. R^2: 0.1160.\n",
      "INFO:root:Epoch 13,200. Training loss: 6.2661. R^2: 0.1159.\n",
      "INFO:root:Epoch 13,300. Training loss: 6.2680. R^2: 0.1157.\n",
      "INFO:root:Epoch 13,400. Training loss: 6.2706. R^2: 0.1153.\n",
      "INFO:root:Epoch 13,500. Training loss: 6.2695. R^2: 0.1155.\n",
      "INFO:root:Epoch 13,600. Training loss: 6.2667. R^2: 0.1159.\n",
      "INFO:root:Epoch 13,700. Training loss: 6.2645. R^2: 0.1162.\n",
      "INFO:root:Epoch 13,800. Training loss: 6.2648. R^2: 0.1161.\n",
      "INFO:root:Epoch 13,900. Training loss: 6.2685. R^2: 0.1156.\n",
      "INFO:root:Epoch 14,000. Training loss: 6.2682. R^2: 0.1156.\n",
      "INFO:root:Epoch 14,100. Training loss: 6.2649. R^2: 0.1161.\n",
      "INFO:root:Epoch 14,200. Training loss: 6.2629. R^2: 0.1164.\n",
      "INFO:root:Epoch 14,300. Training loss: 6.2619. R^2: 0.1165.\n",
      "INFO:root:Epoch 14,400. Training loss: 6.2659. R^2: 0.1160.\n",
      "INFO:root:Epoch 14,500. Training loss: 6.2674. R^2: 0.1158.\n",
      "INFO:root:Epoch 14,600. Training loss: 6.2641. R^2: 0.1162.\n",
      "INFO:root:Epoch 14,700. Training loss: 6.2616. R^2: 0.1166.\n",
      "INFO:root:Epoch 14,800. Training loss: 6.2611. R^2: 0.1166.\n",
      "INFO:root:Epoch 14,900. Training loss: 6.2644. R^2: 0.1162.\n",
      "INFO:root:Epoch 15,000. Training loss: 6.2670. R^2: 0.1158.\n",
      "INFO:root:Epoch 15,100. Training loss: 6.2646. R^2: 0.1162.\n",
      "INFO:root:Epoch 15,200. Training loss: 6.2607. R^2: 0.1167.\n",
      "INFO:root:Epoch 15,300. Training loss: 6.2588. R^2: 0.1170.\n",
      "INFO:root:Epoch 15,400. Training loss: 6.2597. R^2: 0.1169.\n",
      "INFO:root:Epoch 15,500. Training loss: 6.2630. R^2: 0.1164.\n",
      "INFO:root:Epoch 15,600. Training loss: 6.2654. R^2: 0.1160.\n",
      "INFO:root:Epoch 15,700. Training loss: 6.2615. R^2: 0.1166.\n",
      "INFO:root:Epoch 15,800. Training loss: 6.2580. R^2: 0.1171.\n",
      "INFO:root:Epoch 15,900. Training loss: 6.2581. R^2: 0.1171.\n",
      "INFO:root:Epoch 16,000. Training loss: 6.2606. R^2: 0.1167.\n",
      "INFO:root:Epoch 16,100. Training loss: 6.2626. R^2: 0.1164.\n",
      "INFO:root:Epoch 16,200. Training loss: 6.2636. R^2: 0.1163.\n",
      "INFO:root:Epoch 16,300. Training loss: 6.2634. R^2: 0.1163.\n",
      "INFO:root:Epoch 16,400. Training loss: 6.2632. R^2: 0.1164.\n",
      "INFO:root:Epoch 16,500. Training loss: 6.2626. R^2: 0.1164.\n",
      "INFO:root:Epoch 16,600. Training loss: 6.2625. R^2: 0.1165.\n",
      "INFO:root:Epoch 16,700. Training loss: 6.2597. R^2: 0.1168.\n",
      "INFO:root:Epoch 16,800. Training loss: 6.2577. R^2: 0.1171.\n",
      "INFO:root:Epoch 16,900. Training loss: 6.2564. R^2: 0.1173.\n",
      "INFO:root:Epoch 17,000. Training loss: 6.2548. R^2: 0.1175.\n",
      "INFO:root:Epoch 17,100. Training loss: 6.2545. R^2: 0.1176.\n",
      "INFO:root:Epoch 17,200. Training loss: 6.2538. R^2: 0.1177.\n",
      "INFO:root:Epoch 17,300. Training loss: 6.2538. R^2: 0.1177.\n",
      "INFO:root:Epoch 17,400. Training loss: 6.2543. R^2: 0.1176.\n",
      "INFO:root:Epoch 17,500. Training loss: 6.2544. R^2: 0.1176.\n",
      "INFO:root:Epoch 17,600. Training loss: 6.2547. R^2: 0.1176.\n",
      "INFO:root:Epoch 17,700. Training loss: 6.2545. R^2: 0.1176.\n",
      "INFO:root:Epoch 17,800. Training loss: 6.2553. R^2: 0.1175.\n",
      "INFO:root:Epoch 17,900. Training loss: 6.2569. R^2: 0.1172.\n",
      "INFO:root:Epoch 18,000. Training loss: 6.2585. R^2: 0.1170.\n",
      "INFO:root:Epoch 18,100. Training loss: 6.2599. R^2: 0.1168.\n",
      "INFO:root:Epoch 18,200. Training loss: 6.2590. R^2: 0.1169.\n",
      "INFO:root:Epoch 18,300. Training loss: 6.2586. R^2: 0.1170.\n",
      "INFO:root:Epoch 18,400. Training loss: 6.2565. R^2: 0.1173.\n",
      "INFO:root:Epoch 18,500. Training loss: 6.2563. R^2: 0.1173.\n",
      "INFO:root:Epoch 18,600. Training loss: 6.2556. R^2: 0.1174.\n",
      "INFO:root:Epoch 18,700. Training loss: 6.2556. R^2: 0.1174.\n",
      "INFO:root:Epoch 18,800. Training loss: 6.2555. R^2: 0.1174.\n",
      "INFO:root:Epoch 18,900. Training loss: 6.2545. R^2: 0.1176.\n",
      "INFO:root:Epoch 19,000. Training loss: 6.2539. R^2: 0.1177.\n",
      "INFO:root:Epoch 19,100. Training loss: 6.2525. R^2: 0.1179.\n",
      "INFO:root:Epoch 19,200. Training loss: 6.2527. R^2: 0.1178.\n",
      "INFO:root:Epoch 19,300. Training loss: 6.2540. R^2: 0.1176.\n",
      "INFO:root:Epoch 19,400. Training loss: 6.2546. R^2: 0.1176.\n",
      "INFO:root:Epoch 19,500. Training loss: 6.2552. R^2: 0.1175.\n",
      "INFO:root:Epoch 19,600. Training loss: 6.2560. R^2: 0.1174.\n",
      "INFO:root:Epoch 19,700. Training loss: 6.2555. R^2: 0.1174.\n",
      "INFO:root:Epoch 19,800. Training loss: 6.2557. R^2: 0.1174.\n",
      "INFO:root:Epoch 19,900. Training loss: 6.2550. R^2: 0.1175.\n",
      "INFO:root:Training complete.\n"
     ]
    }
   ],
   "source": [
    "model_trainer1.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba26a52-61ae-4d1f-a0b6-21f65481b0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train loss 6.255. R^2: 0.118.\n",
      "INFO:root:Test loss 5.924. R^2: 0.112.\n"
     ]
    }
   ],
   "source": [
    "loss_train = model_trainer1.model.loss(x_train, y_train)\n",
    "r2_score_train = 1 - train_loss/jnp.var(y_train)\n",
    "\n",
    "loss_test = model_trainer1.model.loss(x_test, y_test)\n",
    "r2_score_test = 1 - test_loss/jnp.var(y_test)\n",
    "\n",
    "logging.info(f'Train loss {loss_train:.3f}. R^2: {r2_score_train:.3f}.')\n",
    "logging.info(f'Test loss {loss_test:.3f}. R^2: {r2_score_test:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "714363c9-8b8d-4907-91eb-a97bba68a5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./__state__/local_model_trainer.pkl', 'wb') as file:\n",
    "    dill.dump(model_trainer1, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256966b-7402-47b5-99ea-4af8c0f7eddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Symmetric Local Window Fully Connected Model\n",
    "Similar to the past model, but where the symmetry of GERP score with respect to a sequence and its reverse complement is hardcoded in the sequence structure.\n",
    "\n",
    "It seems to perform a little worse than the unrestricted local window model above. This makes sense, since it is a constrained version of the former. This difference can be used to separate the sequence dependent variation that is strand independent (i.e. symmetric) from the sequence dependent variation that is strand dependent (i.e. not symmetric). Though a more rigorous way of handling this is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a13683d-19b3-4625-bfb5-0cd401515880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = SymmetricLocalWindowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76b996ed-7ced-482d-af26-6c1eaf8e17a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_trainer2 = ModelTrainer(model2, epochs=20000, optimizer=optax.sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2266b6e8-3ccf-4106-82e2-76e77e547cd4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 7.3228. R^2: -0.0331.\n",
      "INFO:root:Epoch 100. Training loss: 6.7698. R^2: 0.0449.\n",
      "INFO:root:Epoch 200. Training loss: 6.6704. R^2: 0.0589.\n",
      "INFO:root:Epoch 300. Training loss: 6.6389. R^2: 0.0634.\n",
      "INFO:root:Epoch 400. Training loss: 6.6195. R^2: 0.0661.\n",
      "INFO:root:Epoch 500. Training loss: 6.6054. R^2: 0.0681.\n",
      "INFO:root:Epoch 600. Training loss: 6.5956. R^2: 0.0695.\n",
      "INFO:root:Epoch 700. Training loss: 6.5878. R^2: 0.0706.\n",
      "INFO:root:Epoch 800. Training loss: 6.5813. R^2: 0.0715.\n",
      "INFO:root:Epoch 900. Training loss: 6.5750. R^2: 0.0724.\n",
      "INFO:root:Epoch 1,000. Training loss: 6.5698. R^2: 0.0731.\n",
      "INFO:root:Epoch 1,100. Training loss: 6.5646. R^2: 0.0738.\n",
      "INFO:root:Epoch 1,200. Training loss: 6.5604. R^2: 0.0744.\n",
      "INFO:root:Epoch 1,300. Training loss: 6.5563. R^2: 0.0750.\n",
      "INFO:root:Epoch 1,400. Training loss: 6.5523. R^2: 0.0756.\n",
      "INFO:root:Epoch 1,500. Training loss: 6.5487. R^2: 0.0761.\n",
      "INFO:root:Epoch 1,600. Training loss: 6.5453. R^2: 0.0766.\n",
      "INFO:root:Epoch 1,700. Training loss: 6.5423. R^2: 0.0770.\n",
      "INFO:root:Epoch 1,800. Training loss: 6.5395. R^2: 0.0774.\n",
      "INFO:root:Epoch 1,900. Training loss: 6.5371. R^2: 0.0777.\n",
      "INFO:root:Epoch 2,000. Training loss: 6.5344. R^2: 0.0781.\n",
      "INFO:root:Epoch 2,100. Training loss: 6.5326. R^2: 0.0783.\n",
      "INFO:root:Epoch 2,200. Training loss: 6.5307. R^2: 0.0786.\n",
      "INFO:root:Epoch 2,300. Training loss: 6.5285. R^2: 0.0789.\n",
      "INFO:root:Epoch 2,400. Training loss: 6.5269. R^2: 0.0791.\n",
      "INFO:root:Epoch 2,500. Training loss: 6.5253. R^2: 0.0794.\n",
      "INFO:root:Epoch 2,600. Training loss: 6.5237. R^2: 0.0796.\n",
      "INFO:root:Epoch 2,700. Training loss: 6.5223. R^2: 0.0798.\n",
      "INFO:root:Epoch 2,800. Training loss: 6.5212. R^2: 0.0800.\n",
      "INFO:root:Epoch 2,900. Training loss: 6.5198. R^2: 0.0802.\n",
      "INFO:root:Epoch 3,000. Training loss: 6.5188. R^2: 0.0803.\n",
      "INFO:root:Epoch 3,100. Training loss: 6.5175. R^2: 0.0805.\n",
      "INFO:root:Epoch 3,200. Training loss: 6.5162. R^2: 0.0807.\n",
      "INFO:root:Epoch 3,300. Training loss: 6.5152. R^2: 0.0808.\n",
      "INFO:root:Epoch 3,400. Training loss: 6.5144. R^2: 0.0809.\n",
      "INFO:root:Epoch 3,500. Training loss: 6.5135. R^2: 0.0810.\n",
      "INFO:root:Epoch 3,600. Training loss: 6.5124. R^2: 0.0812.\n",
      "INFO:root:Epoch 3,700. Training loss: 6.5120. R^2: 0.0813.\n",
      "INFO:root:Epoch 3,800. Training loss: 6.5109. R^2: 0.0814.\n",
      "INFO:root:Epoch 3,900. Training loss: 6.5101. R^2: 0.0815.\n",
      "INFO:root:Epoch 4,000. Training loss: 6.5091. R^2: 0.0817.\n",
      "INFO:root:Epoch 4,100. Training loss: 6.5085. R^2: 0.0817.\n",
      "INFO:root:Epoch 4,200. Training loss: 6.5069. R^2: 0.0820.\n",
      "INFO:root:Epoch 4,300. Training loss: 6.5068. R^2: 0.0820.\n",
      "INFO:root:Epoch 4,400. Training loss: 6.5057. R^2: 0.0821.\n",
      "INFO:root:Epoch 4,500. Training loss: 6.5054. R^2: 0.0822.\n",
      "INFO:root:Epoch 4,600. Training loss: 6.5041. R^2: 0.0824.\n",
      "INFO:root:Epoch 4,700. Training loss: 6.5036. R^2: 0.0824.\n",
      "INFO:root:Epoch 4,800. Training loss: 6.5036. R^2: 0.0824.\n",
      "INFO:root:Epoch 4,900. Training loss: 6.5022. R^2: 0.0826.\n",
      "INFO:root:Epoch 5,000. Training loss: 6.5016. R^2: 0.0827.\n",
      "INFO:root:Epoch 5,100. Training loss: 6.5021. R^2: 0.0827.\n",
      "INFO:root:Epoch 5,200. Training loss: 6.5001. R^2: 0.0829.\n",
      "INFO:root:Epoch 5,300. Training loss: 6.5005. R^2: 0.0829.\n",
      "INFO:root:Epoch 5,400. Training loss: 6.4996. R^2: 0.0830.\n",
      "INFO:root:Epoch 5,500. Training loss: 6.4981. R^2: 0.0832.\n",
      "INFO:root:Epoch 5,600. Training loss: 6.4982. R^2: 0.0832.\n",
      "INFO:root:Epoch 5,700. Training loss: 6.4988. R^2: 0.0831.\n",
      "INFO:root:Epoch 5,800. Training loss: 6.4984. R^2: 0.0832.\n",
      "INFO:root:Epoch 5,900. Training loss: 6.4966. R^2: 0.0834.\n",
      "INFO:root:Epoch 6,000. Training loss: 6.4953. R^2: 0.0836.\n",
      "INFO:root:Epoch 6,100. Training loss: 6.4951. R^2: 0.0836.\n",
      "INFO:root:Epoch 6,200. Training loss: 6.4948. R^2: 0.0837.\n",
      "INFO:root:Epoch 6,300. Training loss: 6.4959. R^2: 0.0835.\n",
      "INFO:root:Epoch 6,400. Training loss: 6.4958. R^2: 0.0835.\n",
      "INFO:root:Epoch 6,500. Training loss: 6.4943. R^2: 0.0837.\n",
      "INFO:root:Epoch 6,600. Training loss: 6.4932. R^2: 0.0839.\n",
      "INFO:root:Epoch 6,700. Training loss: 6.4926. R^2: 0.0840.\n",
      "INFO:root:Epoch 6,800. Training loss: 6.4937. R^2: 0.0838.\n",
      "INFO:root:Epoch 6,900. Training loss: 6.4939. R^2: 0.0838.\n",
      "INFO:root:Epoch 7,000. Training loss: 6.4940. R^2: 0.0838.\n",
      "INFO:root:Epoch 7,100. Training loss: 6.4935. R^2: 0.0839.\n",
      "INFO:root:Epoch 7,200. Training loss: 6.4926. R^2: 0.0840.\n",
      "INFO:root:Epoch 7,300. Training loss: 6.4919. R^2: 0.0841.\n",
      "INFO:root:Epoch 7,400. Training loss: 6.4908. R^2: 0.0842.\n",
      "INFO:root:Epoch 7,500. Training loss: 6.4899. R^2: 0.0844.\n",
      "INFO:root:Epoch 7,600. Training loss: 6.4895. R^2: 0.0844.\n",
      "INFO:root:Epoch 7,700. Training loss: 6.4893. R^2: 0.0845.\n",
      "INFO:root:Epoch 7,800. Training loss: 6.4890. R^2: 0.0845.\n",
      "INFO:root:Epoch 7,900. Training loss: 6.4889. R^2: 0.0845.\n",
      "INFO:root:Epoch 8,000. Training loss: 6.4891. R^2: 0.0845.\n",
      "INFO:root:Epoch 8,100. Training loss: 6.4893. R^2: 0.0845.\n",
      "INFO:root:Epoch 8,200. Training loss: 6.4894. R^2: 0.0844.\n",
      "INFO:root:Epoch 8,300. Training loss: 6.4894. R^2: 0.0844.\n",
      "INFO:root:Epoch 8,400. Training loss: 6.4895. R^2: 0.0844.\n",
      "INFO:root:Epoch 8,500. Training loss: 6.4887. R^2: 0.0845.\n",
      "INFO:root:Epoch 8,600. Training loss: 6.4877. R^2: 0.0847.\n",
      "INFO:root:Epoch 8,700. Training loss: 6.4866. R^2: 0.0848.\n",
      "INFO:root:Epoch 8,800. Training loss: 6.4860. R^2: 0.0849.\n",
      "INFO:root:Epoch 8,900. Training loss: 6.4854. R^2: 0.0850.\n",
      "INFO:root:Epoch 9,000. Training loss: 6.4848. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,100. Training loss: 6.4846. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,200. Training loss: 6.4845. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,300. Training loss: 6.4842. R^2: 0.0852.\n",
      "INFO:root:Epoch 9,400. Training loss: 6.4844. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,500. Training loss: 6.4846. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,600. Training loss: 6.4846. R^2: 0.0851.\n",
      "INFO:root:Epoch 9,700. Training loss: 6.4852. R^2: 0.0850.\n",
      "INFO:root:Epoch 9,800. Training loss: 6.4858. R^2: 0.0850.\n",
      "INFO:root:Epoch 9,900. Training loss: 6.4860. R^2: 0.0849.\n",
      "INFO:root:Epoch 10,000. Training loss: 6.4856. R^2: 0.0850.\n",
      "INFO:root:Epoch 10,100. Training loss: 6.4850. R^2: 0.0851.\n",
      "INFO:root:Epoch 10,200. Training loss: 6.4840. R^2: 0.0852.\n",
      "INFO:root:Epoch 10,300. Training loss: 6.4835. R^2: 0.0853.\n",
      "INFO:root:Epoch 10,400. Training loss: 6.4833. R^2: 0.0853.\n",
      "INFO:root:Epoch 10,500. Training loss: 6.4822. R^2: 0.0855.\n",
      "INFO:root:Epoch 10,600. Training loss: 6.4817. R^2: 0.0855.\n",
      "INFO:root:Epoch 10,700. Training loss: 6.4809. R^2: 0.0856.\n",
      "INFO:root:Epoch 10,800. Training loss: 6.4813. R^2: 0.0856.\n",
      "INFO:root:Epoch 10,900. Training loss: 6.4813. R^2: 0.0856.\n",
      "INFO:root:Epoch 11,000. Training loss: 6.4815. R^2: 0.0856.\n",
      "INFO:root:Epoch 11,100. Training loss: 6.4817. R^2: 0.0855.\n",
      "INFO:root:Epoch 11,200. Training loss: 6.4820. R^2: 0.0855.\n",
      "INFO:root:Epoch 11,300. Training loss: 6.4826. R^2: 0.0854.\n",
      "INFO:root:Epoch 11,400. Training loss: 6.4828. R^2: 0.0854.\n",
      "INFO:root:Epoch 11,500. Training loss: 6.4825. R^2: 0.0854.\n",
      "INFO:root:Epoch 11,600. Training loss: 6.4820. R^2: 0.0855.\n",
      "INFO:root:Epoch 11,700. Training loss: 6.4821. R^2: 0.0855.\n",
      "INFO:root:Epoch 11,800. Training loss: 6.4815. R^2: 0.0856.\n",
      "INFO:root:Epoch 11,900. Training loss: 6.4808. R^2: 0.0857.\n",
      "INFO:root:Epoch 12,000. Training loss: 6.4799. R^2: 0.0858.\n",
      "INFO:root:Epoch 12,100. Training loss: 6.4795. R^2: 0.0858.\n",
      "INFO:root:Epoch 12,200. Training loss: 6.4787. R^2: 0.0859.\n",
      "INFO:root:Epoch 12,300. Training loss: 6.4779. R^2: 0.0861.\n",
      "INFO:root:Epoch 12,400. Training loss: 6.4771. R^2: 0.0862.\n",
      "INFO:root:Epoch 12,500. Training loss: 6.4773. R^2: 0.0861.\n",
      "INFO:root:Epoch 12,600. Training loss: 6.4786. R^2: 0.0860.\n",
      "INFO:root:Epoch 12,700. Training loss: 6.4796. R^2: 0.0858.\n",
      "INFO:root:Epoch 12,800. Training loss: 6.4793. R^2: 0.0859.\n",
      "INFO:root:Epoch 12,900. Training loss: 6.4782. R^2: 0.0860.\n",
      "INFO:root:Epoch 13,000. Training loss: 6.4770. R^2: 0.0862.\n",
      "INFO:root:Epoch 13,100. Training loss: 6.4761. R^2: 0.0863.\n",
      "INFO:root:Epoch 13,200. Training loss: 6.4760. R^2: 0.0863.\n",
      "INFO:root:Epoch 13,300. Training loss: 6.4760. R^2: 0.0863.\n",
      "INFO:root:Epoch 13,400. Training loss: 6.4763. R^2: 0.0863.\n",
      "INFO:root:Epoch 13,500. Training loss: 6.4766. R^2: 0.0863.\n",
      "INFO:root:Epoch 13,600. Training loss: 6.4773. R^2: 0.0862.\n",
      "INFO:root:Epoch 13,700. Training loss: 6.4779. R^2: 0.0861.\n",
      "INFO:root:Epoch 13,800. Training loss: 6.4784. R^2: 0.0860.\n",
      "INFO:root:Epoch 13,900. Training loss: 6.4776. R^2: 0.0861.\n",
      "INFO:root:Epoch 14,000. Training loss: 6.4764. R^2: 0.0863.\n",
      "INFO:root:Epoch 14,100. Training loss: 6.4750. R^2: 0.0865.\n",
      "INFO:root:Epoch 14,200. Training loss: 6.4740. R^2: 0.0866.\n",
      "INFO:root:Epoch 14,300. Training loss: 6.4734. R^2: 0.0867.\n",
      "INFO:root:Epoch 14,400. Training loss: 6.4734. R^2: 0.0867.\n",
      "INFO:root:Epoch 14,500. Training loss: 6.4735. R^2: 0.0867.\n",
      "INFO:root:Epoch 14,600. Training loss: 6.4733. R^2: 0.0867.\n",
      "INFO:root:Epoch 14,700. Training loss: 6.4728. R^2: 0.0868.\n",
      "INFO:root:Epoch 14,800. Training loss: 6.4723. R^2: 0.0869.\n",
      "INFO:root:Epoch 14,900. Training loss: 6.4717. R^2: 0.0869.\n",
      "INFO:root:Epoch 15,000. Training loss: 6.4718. R^2: 0.0869.\n",
      "INFO:root:Epoch 15,100. Training loss: 6.4717. R^2: 0.0869.\n",
      "INFO:root:Epoch 15,200. Training loss: 6.4722. R^2: 0.0869.\n",
      "INFO:root:Epoch 15,300. Training loss: 6.4728. R^2: 0.0868.\n",
      "INFO:root:Epoch 15,400. Training loss: 6.4735. R^2: 0.0867.\n",
      "INFO:root:Epoch 15,500. Training loss: 6.4739. R^2: 0.0866.\n",
      "INFO:root:Epoch 15,600. Training loss: 6.4741. R^2: 0.0866.\n",
      "INFO:root:Epoch 15,700. Training loss: 6.4745. R^2: 0.0865.\n",
      "INFO:root:Epoch 15,800. Training loss: 6.4747. R^2: 0.0865.\n",
      "INFO:root:Epoch 15,900. Training loss: 6.4740. R^2: 0.0866.\n",
      "INFO:root:Epoch 16,000. Training loss: 6.4730. R^2: 0.0868.\n",
      "INFO:root:Epoch 16,100. Training loss: 6.4716. R^2: 0.0870.\n",
      "INFO:root:Epoch 16,200. Training loss: 6.4719. R^2: 0.0869.\n",
      "INFO:root:Epoch 16,300. Training loss: 6.4715. R^2: 0.0870.\n",
      "INFO:root:Epoch 16,400. Training loss: 6.4706. R^2: 0.0871.\n",
      "INFO:root:Epoch 16,500. Training loss: 6.4709. R^2: 0.0871.\n",
      "INFO:root:Epoch 16,600. Training loss: 6.4712. R^2: 0.0870.\n",
      "INFO:root:Epoch 16,700. Training loss: 6.4720. R^2: 0.0869.\n",
      "INFO:root:Epoch 16,800. Training loss: 6.4723. R^2: 0.0869.\n",
      "INFO:root:Epoch 16,900. Training loss: 6.4723. R^2: 0.0869.\n",
      "INFO:root:Epoch 17,000. Training loss: 6.4728. R^2: 0.0868.\n",
      "INFO:root:Epoch 17,100. Training loss: 6.4725. R^2: 0.0868.\n",
      "INFO:root:Epoch 17,200. Training loss: 6.4718. R^2: 0.0869.\n",
      "INFO:root:Epoch 17,300. Training loss: 6.4710. R^2: 0.0870.\n",
      "INFO:root:Epoch 17,400. Training loss: 6.4713. R^2: 0.0870.\n",
      "INFO:root:Epoch 17,500. Training loss: 6.4706. R^2: 0.0871.\n",
      "INFO:root:Epoch 17,600. Training loss: 6.4703. R^2: 0.0871.\n",
      "INFO:root:Epoch 17,700. Training loss: 6.4700. R^2: 0.0872.\n",
      "INFO:root:Epoch 17,800. Training loss: 6.4696. R^2: 0.0872.\n",
      "INFO:root:Epoch 17,900. Training loss: 6.4688. R^2: 0.0873.\n",
      "INFO:root:Epoch 18,000. Training loss: 6.4679. R^2: 0.0875.\n",
      "INFO:root:Epoch 18,100. Training loss: 6.4679. R^2: 0.0875.\n",
      "INFO:root:Epoch 18,200. Training loss: 6.4675. R^2: 0.0875.\n",
      "INFO:root:Epoch 18,300. Training loss: 6.4675. R^2: 0.0875.\n",
      "INFO:root:Epoch 18,400. Training loss: 6.4674. R^2: 0.0875.\n",
      "INFO:root:Epoch 18,500. Training loss: 6.4667. R^2: 0.0876.\n",
      "INFO:root:Epoch 18,600. Training loss: 6.4661. R^2: 0.0877.\n",
      "INFO:root:Epoch 18,700. Training loss: 6.4664. R^2: 0.0877.\n",
      "INFO:root:Epoch 18,800. Training loss: 6.4660. R^2: 0.0877.\n",
      "INFO:root:Epoch 18,900. Training loss: 6.4658. R^2: 0.0878.\n",
      "INFO:root:Epoch 19,000. Training loss: 6.4658. R^2: 0.0878.\n",
      "INFO:root:Epoch 19,100. Training loss: 6.4653. R^2: 0.0878.\n",
      "INFO:root:Epoch 19,200. Training loss: 6.4652. R^2: 0.0879.\n",
      "INFO:root:Epoch 19,300. Training loss: 6.4656. R^2: 0.0878.\n",
      "INFO:root:Epoch 19,400. Training loss: 6.4659. R^2: 0.0878.\n",
      "INFO:root:Epoch 19,500. Training loss: 6.4663. R^2: 0.0877.\n",
      "INFO:root:Epoch 19,600. Training loss: 6.4673. R^2: 0.0876.\n",
      "INFO:root:Epoch 19,700. Training loss: 6.4690. R^2: 0.0873.\n",
      "INFO:root:Epoch 19,800. Training loss: 6.4694. R^2: 0.0873.\n",
      "INFO:root:Epoch 19,900. Training loss: 6.4685. R^2: 0.0874.\n",
      "INFO:root:Training complete.\n"
     ]
    }
   ],
   "source": [
    "model_trainer2.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "184f5b76-c212-4494-9a9c-2f0bf9a43da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train loss 6.466. R^2: 0.088.\n",
      "INFO:root:Test loss 6.102. R^2: 0.085.\n"
     ]
    }
   ],
   "source": [
    "loss_train = model_trainer2.model.loss(x_train, y_train)\n",
    "r2_score_train = 1 - loss_train/jnp.var(y_train)\n",
    "\n",
    "loss_test = model_trainer2.model.loss(x_test, y_test)\n",
    "r2_score_test = 1 - loss_test/jnp.var(y_test)\n",
    "\n",
    "logging.info(f'Train loss {loss_train:.3f}. R^2: {r2_score_train:.3f}.')\n",
    "logging.info(f'Test loss {loss_test:.3f}. R^2: {r2_score_test:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64678be0-8cc2-42ee-951b-ff57d93db4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./__state__/symmetric_local_model_trainer.pkl', 'wb') as file:\n",
    "    dill.dump(model_trainer2, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1346a4-5787-4a9f-88c8-672cd19c2918",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8159094-38ee-4072-b271-f2d1daee87d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Model architecture needs optimization to run in reasonable time\n",
    "model3 = LocalTransformerEncoderModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "901fb37f-875c-436f-9a23-b1f40ad49b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.9228151], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78cfb572-92b6-4da5-897d-dffed123daa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(9.713807, dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.loss(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb172406-5d47-4bcf-8b37-54825ac379a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_trainer3 = ModelTrainer(model3, epochs=100, optimizer=optax.sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "017fa8cf-f3f3-46f3-ba7d-c2f02d8cd46d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 11.3904. R^2: -0.6109.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_trainer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/score_modeling.py:98\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m var_y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvar(y)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     periodic_logging(i, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. R^2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mloss_value\u001b[38;5;241m/\u001b[39mvar_y\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, v\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    101\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:70\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun_wrapper(\u001b[38;5;28;01mFalse\u001b[39;00m, args, kwargs)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:59\u001b[0m, in \u001b[0;36m_JitWrapper._fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached\u001b[38;5;241m.\u001b[39mlower(dynamic, static)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     dynamic_out, static_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combine(dynamic_out, static_out\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/module.py:285\u001b[0m, in \u001b[0;36mModule._tree_unflatten\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    278\u001b[0m             static_field_values\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(dynamic_field_values), (\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_names),\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_values),\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, aux, dynamic_field_values):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    288\u001b[0m     dynamic_field_names, static_field_names, static_field_values \u001b[38;5;241m=\u001b[39m aux\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer3.train(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gene_venv",
   "language": "python",
   "name": "gene_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
