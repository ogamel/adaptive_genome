{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844faf10-c25c-4575-8dc5-a0a27bee6af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "Here we explore training of neural networks that predict the GERP score from the sequence. We try multiple network architectures and report the results of each.\n",
    "\n",
    "\n",
    "Inversion symmetry of score implies local window should extend both sides equally - since if one sequence affects only in one direction, its revetrse complement will affect in the opposite direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e3bde-7fce-492d-9ab4-3357fb905ca8",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd48c92b-72e2-4b3f-a791-2e4e28c9ffd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from data.load import read_sequence, read_annotation_generator, examine_annotation, read_gerp_scorer\n",
    "from data.paths import chr17_paths # paths to source data files\n",
    "from data.process import get_train_test_x_y\n",
    "\n",
    "from score_modeling import LocalWindowModel, LocalTransformerEncoderModel, ModelTrainer\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1bef3d-9964-40d3-84a2-6399b9f1e022",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 200\n",
    "\n",
    "# display options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d45369b2-2b25-4c87-bd62-e17ac9658fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e3754-2530-49cb-8090-8ea1405cb17c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0262bdf-26bb-4de9-981d-ec95f79d1070",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start the analysis with human chromosome 17\n",
    "paths = chr17_paths\n",
    "\n",
    "# get the raw sequence dictionary, from a FASTA file\n",
    "seq_dict = read_sequence(paths.sequence)\n",
    "\n",
    "# # (optional) examine annotations, from the annotation GFF file\n",
    "# examine_annotation(paths.annotation)\n",
    "\n",
    "# get the annotated sequence generator function, from the annotation GFF file\n",
    "seq_records_gen = read_annotation_generator(paths.annotation, seq_dict=seq_dict)\n",
    "\n",
    "# get GERP retrieval function, from the BigWig file\n",
    "gerp_scorer = read_gerp_scorer(paths.gerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "029b2722-b194-4240-a17b-8f727cb16f4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Sequence 17 ...\n",
      "INFO:root:Traversing feature tree ...\n",
      "INFO:root:Traversed feature tree in 202,358 iterations. Extracted 54,544 features.\n",
      "INFO:root:Processing feature 0. x_train shape: (0, 76)\n",
      "INFO:root:Processing feature 100. x_train shape: (9992, 76)\n",
      "INFO:root:Processing feature 200. x_train shape: (15608, 76)\n",
      "INFO:root:Processing feature 300. x_train shape: (23115, 76)\n",
      "INFO:root:Processing feature 400. x_train shape: (30534, 76)\n",
      "INFO:root:Processing feature 500. x_train shape: (37718, 76)\n",
      "INFO:root:Processing feature 600. x_train shape: (45469, 76)\n",
      "INFO:root:Processing feature 700. x_train shape: (52701, 76)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_test_x_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_records_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgerp_scorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCDS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/data/process.py:96\u001b[0m, in \u001b[0;36mget_train_test_x_y\u001b[0;34m(seq_records_gen, scorer, feature_type_filter)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_indices:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# append to train\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mappend(x_train, ft_x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mappend(y_train, ft_y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# append to test\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     x_test \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mappend(x_test, ft_x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/pjit.py:235\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 235\u001b[0m   outs, out_flat, out_tree, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_params_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable()\n\u001b[1;32m    240\u001b[0m   use_fastpath \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    241\u001b[0m       executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    242\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(executable, pxla\u001b[38;5;241m.\u001b[39mMeshExecutable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, xc\u001b[38;5;241m.\u001b[39mArrayImpl) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out_flat)\n\u001b[1;32m    249\u001b[0m   )\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/pjit.py:184\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    186\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/core.py:2577\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2573\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2574\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2575\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2576\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/core.py:807\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/pjit.py:1291\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, in_positional_semantics, out_positional_semantics, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m   _allow_propagation_to_outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_shardings)\n\u001b[0;32m-> 1291\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_is_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1295\u001b[0m         _allow_propagation_to_outputs\u001b[38;5;241m=\u001b[39m_allow_propagation_to_outputs)\n\u001b[1;32m   1296\u001b[0m _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/pjit.py:1377\u001b[0m, in \u001b[0;36m_pjit_lower\u001b[0;34m(jaxpr, in_shardings, out_shardings, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(in_shardings, da)\n\u001b[1;32m   1376\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(out_shardings, da)\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pjit_lower_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/jax/_src/pjit.py:1380\u001b[0m, in \u001b[0;36m_pjit_lower_cached\u001b[0;34m(jaxpr, sdat_in_shardings, sdat_out_shardings, resource_env, donated_invars, name, in_is_global, keep_unused, always_lower, lowering_platform)\u001b[0m\n\u001b[1;32m   1376\u001b[0m   out_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(out_shardings, da)\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _pjit_lower_cached(jaxpr, in_shardings, out_shardings, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1380\u001b[0m \u001b[38;5;129m@weakref_lru_cache\u001b[39m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pjit_lower_cached\u001b[39m(\n\u001b[1;32m   1382\u001b[0m     jaxpr: core\u001b[38;5;241m.\u001b[39mClosedJaxpr,\n\u001b[1;32m   1383\u001b[0m     sdat_in_shardings: SameDeviceAssignmentTuple,\n\u001b[1;32m   1384\u001b[0m     sdat_out_shardings: SameDeviceAssignmentTuple,\n\u001b[1;32m   1385\u001b[0m     resource_env,\n\u001b[1;32m   1386\u001b[0m     donated_invars,\n\u001b[1;32m   1387\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1388\u001b[0m     in_is_global: Sequence[\u001b[38;5;28mbool\u001b[39m],\n\u001b[1;32m   1389\u001b[0m     keep_unused: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   1390\u001b[0m     always_lower: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1392\u001b[0m     lowering_platform: Optional[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[1;32m   1393\u001b[0m   in_shardings: Tuple[PjitShardingMinusUnspecified, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1394\u001b[0m       Tuple[PjitShardingMinusUnspecified, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], sdat_in_shardings\u001b[38;5;241m.\u001b[39mshardings)\n\u001b[1;32m   1395\u001b[0m   out_shardings: Tuple[PjitSharding, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m sdat_out_shardings\u001b[38;5;241m.\u001b[39mshardings\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# One hot encode the sequence in a sliding window\n",
    "x_train, y_train, x_test, y_test = get_train_test_x_y(seq_records_gen, gerp_scorer, ['CDS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83c565-f51f-491d-8e29-5ba8bb231900",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Models\n",
    "Here we train different neural network architectures, and rate them with the mean square error loss as well as R^2, which measures the proportion of the variance in the scores we are trying to predict that is explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d3f1d-3992-4ee6-ba32-e0a7a930f448",
   "metadata": {},
   "source": [
    "## Local Window Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241ffd5e-e11b-47e9-9fa2-8462fe124ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = LocalWindowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b097e90-c861-4bdb-9371-8b1e7b441896",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 7.9045. R^2: -0.1179.\n",
      "INFO:root:Epoch 10. Training loss: 7.0631. R^2: 0.0011.\n",
      "INFO:root:Epoch 20. Training loss: 7.0472. R^2: 0.0033.\n",
      "INFO:root:Epoch 30. Training loss: 7.0077. R^2: 0.0089.\n",
      "INFO:root:Epoch 40. Training loss: 6.8796. R^2: 0.0270.\n",
      "INFO:root:Epoch 50. Training loss: 6.5478. R^2: 0.0740.\n",
      "INFO:root:Epoch 60. Training loss: 6.4314. R^2: 0.0904.\n",
      "INFO:root:Epoch 70. Training loss: 6.9480. R^2: 0.0174.\n",
      "INFO:root:Epoch 80. Training loss: 6.4350. R^2: 0.0899.\n",
      "INFO:root:Epoch 90. Training loss: 6.3442. R^2: 0.1028.\n",
      "INFO:root:Epoch 100. Training loss: 6.7097. R^2: 0.0511.\n",
      "INFO:root:Epoch 110. Training loss: 6.4268. R^2: 0.0911.\n",
      "INFO:root:Epoch 120. Training loss: 6.3589. R^2: 0.1007.\n",
      "INFO:root:Epoch 130. Training loss: 6.3735. R^2: 0.0986.\n",
      "INFO:root:Epoch 140. Training loss: 6.3497. R^2: 0.1020.\n",
      "INFO:root:Epoch 150. Training loss: 6.3288. R^2: 0.1049.\n",
      "INFO:root:Epoch 160. Training loss: 6.3154. R^2: 0.1068.\n",
      "INFO:root:Epoch 170. Training loss: 6.3038. R^2: 0.1085.\n",
      "INFO:root:Epoch 180. Training loss: 6.2923. R^2: 0.1101.\n",
      "INFO:root:Epoch 190. Training loss: 6.2854. R^2: 0.1111.\n",
      "INFO:root:Epoch 200. Training loss: 6.2702. R^2: 0.1132.\n",
      "INFO:root:Epoch 210. Training loss: 6.2610. R^2: 0.1145.\n",
      "INFO:root:Epoch 220. Training loss: 6.2516. R^2: 0.1159.\n",
      "INFO:root:Epoch 230. Training loss: 6.2435. R^2: 0.1170.\n",
      "INFO:root:Epoch 240. Training loss: 6.2302. R^2: 0.1189.\n",
      "INFO:root:Epoch 250. Training loss: 6.2202. R^2: 0.1203.\n",
      "INFO:root:Epoch 260. Training loss: 6.2135. R^2: 0.1212.\n",
      "INFO:root:Epoch 270. Training loss: 6.2009. R^2: 0.1230.\n",
      "INFO:root:Epoch 280. Training loss: 6.1878. R^2: 0.1249.\n",
      "INFO:root:Epoch 290. Training loss: 6.1804. R^2: 0.1259.\n",
      "INFO:root:Epoch 300. Training loss: 6.1685. R^2: 0.1276.\n",
      "INFO:root:Epoch 310. Training loss: 6.1491. R^2: 0.1304.\n",
      "INFO:root:Epoch 320. Training loss: 6.1403. R^2: 0.1316.\n",
      "INFO:root:Epoch 330. Training loss: 6.1440. R^2: 0.1311.\n",
      "INFO:root:Epoch 340. Training loss: 6.1218. R^2: 0.1342.\n",
      "INFO:root:Epoch 350. Training loss: 6.0996. R^2: 0.1374.\n",
      "INFO:root:Epoch 360. Training loss: 6.0869. R^2: 0.1392.\n",
      "INFO:root:Epoch 370. Training loss: 6.0799. R^2: 0.1401.\n",
      "INFO:root:Epoch 380. Training loss: 6.0710. R^2: 0.1414.\n",
      "INFO:root:Epoch 390. Training loss: 6.0608. R^2: 0.1428.\n",
      "INFO:root:Epoch 400. Training loss: 6.0616. R^2: 0.1427.\n",
      "INFO:root:Epoch 410. Training loss: 6.0441. R^2: 0.1452.\n",
      "INFO:root:Epoch 420. Training loss: 6.0184. R^2: 0.1488.\n",
      "INFO:root:Epoch 430. Training loss: 5.9963. R^2: 0.1520.\n",
      "INFO:root:Epoch 440. Training loss: 5.9844. R^2: 0.1536.\n",
      "INFO:root:Epoch 450. Training loss: 5.9777. R^2: 0.1546.\n",
      "INFO:root:Epoch 460. Training loss: 5.9728. R^2: 0.1553.\n",
      "INFO:root:Epoch 470. Training loss: 5.9676. R^2: 0.1560.\n",
      "INFO:root:Epoch 480. Training loss: 5.9620. R^2: 0.1568.\n",
      "INFO:root:Epoch 490. Training loss: 5.9534. R^2: 0.1580.\n",
      "INFO:root:Epoch 500. Training loss: 5.9374. R^2: 0.1603.\n",
      "INFO:root:Epoch 510. Training loss: 5.9254. R^2: 0.1620.\n",
      "INFO:root:Epoch 520. Training loss: 5.9084. R^2: 0.1644.\n",
      "INFO:root:Epoch 530. Training loss: 5.8881. R^2: 0.1673.\n",
      "INFO:root:Epoch 540. Training loss: 5.8704. R^2: 0.1698.\n",
      "INFO:root:Epoch 550. Training loss: 5.8551. R^2: 0.1719.\n",
      "INFO:root:Epoch 560. Training loss: 5.8546. R^2: 0.1720.\n",
      "INFO:root:Epoch 570. Training loss: 5.8624. R^2: 0.1709.\n",
      "INFO:root:Epoch 580. Training loss: 5.8675. R^2: 0.1702.\n",
      "INFO:root:Epoch 590. Training loss: 5.8587. R^2: 0.1714.\n",
      "INFO:root:Epoch 600. Training loss: 5.8379. R^2: 0.1744.\n",
      "INFO:root:Epoch 610. Training loss: 5.8141. R^2: 0.1777.\n",
      "INFO:root:Epoch 620. Training loss: 5.7947. R^2: 0.1805.\n",
      "INFO:root:Epoch 630. Training loss: 5.7838. R^2: 0.1820.\n",
      "INFO:root:Epoch 640. Training loss: 5.7904. R^2: 0.1811.\n",
      "INFO:root:Epoch 650. Training loss: 5.7952. R^2: 0.1804.\n",
      "INFO:root:Epoch 660. Training loss: 5.7913. R^2: 0.1810.\n",
      "INFO:root:Epoch 670. Training loss: 5.7875. R^2: 0.1815.\n",
      "INFO:root:Epoch 680. Training loss: 5.7807. R^2: 0.1825.\n",
      "INFO:root:Epoch 690. Training loss: 5.7624. R^2: 0.1851.\n",
      "INFO:root:Epoch 700. Training loss: 5.7458. R^2: 0.1874.\n",
      "INFO:root:Epoch 710. Training loss: 5.7210. R^2: 0.1909.\n",
      "INFO:root:Epoch 720. Training loss: 5.7056. R^2: 0.1931.\n",
      "INFO:root:Epoch 730. Training loss: 5.6982. R^2: 0.1941.\n",
      "INFO:root:Epoch 740. Training loss: 5.6983. R^2: 0.1941.\n",
      "INFO:root:Epoch 750. Training loss: 5.7055. R^2: 0.1931.\n",
      "INFO:root:Epoch 760. Training loss: 5.7169. R^2: 0.1915.\n",
      "INFO:root:Epoch 770. Training loss: 5.7157. R^2: 0.1917.\n",
      "INFO:root:Epoch 780. Training loss: 5.7006. R^2: 0.1938.\n",
      "INFO:root:Epoch 790. Training loss: 5.6828. R^2: 0.1963.\n",
      "INFO:root:Epoch 800. Training loss: 5.6643. R^2: 0.1989.\n",
      "INFO:root:Epoch 810. Training loss: 5.6472. R^2: 0.2013.\n",
      "INFO:root:Epoch 820. Training loss: 5.6254. R^2: 0.2044.\n",
      "INFO:root:Epoch 830. Training loss: 5.6174. R^2: 0.2056.\n",
      "INFO:root:Epoch 840. Training loss: 5.6023. R^2: 0.2077.\n",
      "INFO:root:Epoch 850. Training loss: 5.5914. R^2: 0.2092.\n",
      "INFO:root:Epoch 860. Training loss: 5.6018. R^2: 0.2078.\n",
      "INFO:root:Epoch 870. Training loss: 5.6159. R^2: 0.2058.\n",
      "INFO:root:Epoch 880. Training loss: 5.6220. R^2: 0.2049.\n",
      "INFO:root:Epoch 890. Training loss: 5.6167. R^2: 0.2057.\n",
      "INFO:root:Epoch 900. Training loss: 5.6027. R^2: 0.2076.\n",
      "INFO:root:Epoch 910. Training loss: 5.5721. R^2: 0.2120.\n",
      "INFO:root:Epoch 920. Training loss: 5.5390. R^2: 0.2166.\n",
      "INFO:root:Epoch 930. Training loss: 5.5353. R^2: 0.2172.\n",
      "INFO:root:Epoch 940. Training loss: 5.5664. R^2: 0.2128.\n",
      "INFO:root:Epoch 950. Training loss: 5.5788. R^2: 0.2110.\n",
      "INFO:root:Epoch 960. Training loss: 5.5488. R^2: 0.2153.\n",
      "INFO:root:Epoch 970. Training loss: 5.5127. R^2: 0.2204.\n",
      "INFO:root:Epoch 980. Training loss: 5.4936. R^2: 0.2231.\n",
      "INFO:root:Epoch 990. Training loss: 5.5147. R^2: 0.2201.\n",
      "INFO:root:Training complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LocalWindowModel(\n",
       "  layers=[\n",
       "    Linear(\n",
       "      weight=f32[38,76],\n",
       "      bias=f32[38],\n",
       "      in_features=76,\n",
       "      out_features=38,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[38,38],\n",
       "      bias=f32[38],\n",
       "      in_features=38,\n",
       "      out_features=38,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[38,38],\n",
       "      bias=f32[38],\n",
       "      in_features=38,\n",
       "      out_features=38,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[1,38],\n",
       "      bias=f32[1],\n",
       "      in_features=38,\n",
       "      out_features=1,\n",
       "      use_bias=True\n",
       "    )\n",
       "  ],\n",
       "  extra_bias=f32[1]\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer = ModelTrainer(model1, epochs=10000, optimizer=optax.sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdd9b78b-ecea-4906-9647-8632c0935bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 3.4208. R^2: 0.5162.\n",
      "INFO:root:Epoch 100. Training loss: 3.2799. R^2: 0.5361.\n",
      "INFO:root:Epoch 200. Training loss: 3.2976. R^2: 0.5336.\n",
      "INFO:root:Epoch 300. Training loss: 3.4027. R^2: 0.5188.\n",
      "INFO:root:Epoch 400. Training loss: 3.2364. R^2: 0.5423.\n",
      "INFO:root:Epoch 500. Training loss: 3.4585. R^2: 0.5109.\n",
      "INFO:root:Epoch 600. Training loss: 3.4584. R^2: 0.5109.\n",
      "INFO:root:Epoch 700. Training loss: 3.4705. R^2: 0.5092.\n",
      "INFO:root:Epoch 800. Training loss: 3.1952. R^2: 0.5481.\n",
      "INFO:root:Epoch 900. Training loss: 3.3950. R^2: 0.5199.\n",
      "INFO:root:Epoch 1,000. Training loss: 3.2941. R^2: 0.5341.\n",
      "INFO:root:Epoch 1,100. Training loss: 3.3498. R^2: 0.5262.\n",
      "INFO:root:Epoch 1,200. Training loss: 3.2208. R^2: 0.5445.\n",
      "INFO:root:Epoch 1,300. Training loss: 3.2711. R^2: 0.5374.\n",
      "INFO:root:Epoch 1,400. Training loss: 3.6242. R^2: 0.4874.\n",
      "INFO:root:Epoch 1,500. Training loss: 3.5987. R^2: 0.4911.\n",
      "INFO:root:Epoch 1,600. Training loss: 3.2915. R^2: 0.5345.\n",
      "INFO:root:Epoch 1,700. Training loss: 3.2148. R^2: 0.5453.\n",
      "INFO:root:Epoch 1,800. Training loss: 3.6971. R^2: 0.4771.\n",
      "INFO:root:Epoch 1,900. Training loss: 3.1861. R^2: 0.5494.\n",
      "INFO:root:Epoch 2,000. Training loss: 3.4382. R^2: 0.5137.\n",
      "INFO:root:Epoch 2,100. Training loss: 3.2792. R^2: 0.5362.\n",
      "INFO:root:Epoch 2,200. Training loss: 3.6506. R^2: 0.4837.\n",
      "INFO:root:Epoch 2,300. Training loss: 3.2447. R^2: 0.5411.\n",
      "INFO:root:Epoch 2,400. Training loss: 3.2209. R^2: 0.5445.\n",
      "INFO:root:Epoch 2,500. Training loss: 3.3000. R^2: 0.5333.\n",
      "INFO:root:Epoch 2,600. Training loss: 3.5301. R^2: 0.5007.\n",
      "INFO:root:Epoch 2,700. Training loss: 3.1527. R^2: 0.5541.\n",
      "INFO:root:Epoch 2,800. Training loss: 3.1643. R^2: 0.5525.\n",
      "INFO:root:Epoch 2,900. Training loss: 3.3943. R^2: 0.5200.\n",
      "INFO:root:Epoch 3,000. Training loss: 3.2812. R^2: 0.5360.\n",
      "INFO:root:Epoch 3,100. Training loss: 3.3227. R^2: 0.5301.\n",
      "INFO:root:Epoch 3,200. Training loss: 3.3436. R^2: 0.5271.\n",
      "INFO:root:Epoch 3,300. Training loss: 3.2666. R^2: 0.5380.\n",
      "INFO:root:Epoch 3,400. Training loss: 3.2733. R^2: 0.5371.\n",
      "INFO:root:Epoch 3,500. Training loss: 3.3336. R^2: 0.5285.\n",
      "INFO:root:Epoch 3,600. Training loss: 3.4430. R^2: 0.5131.\n",
      "INFO:root:Epoch 3,700. Training loss: 3.2558. R^2: 0.5396.\n",
      "INFO:root:Epoch 3,800. Training loss: 3.3568. R^2: 0.5253.\n",
      "INFO:root:Epoch 3,900. Training loss: 3.2539. R^2: 0.5398.\n",
      "INFO:root:Epoch 4,000. Training loss: 3.4081. R^2: 0.5180.\n",
      "INFO:root:Epoch 4,100. Training loss: 3.3241. R^2: 0.5299.\n",
      "INFO:root:Epoch 4,200. Training loss: 3.5666. R^2: 0.4956.\n",
      "INFO:root:Epoch 4,300. Training loss: 3.2587. R^2: 0.5391.\n",
      "INFO:root:Epoch 4,400. Training loss: 3.1377. R^2: 0.5562.\n",
      "INFO:root:Epoch 4,500. Training loss: 3.2423. R^2: 0.5414.\n",
      "INFO:root:Epoch 4,600. Training loss: 3.2140. R^2: 0.5454.\n",
      "INFO:root:Epoch 4,700. Training loss: 3.4831. R^2: 0.5074.\n",
      "INFO:root:Epoch 4,800. Training loss: 3.1391. R^2: 0.5561.\n",
      "INFO:root:Epoch 4,900. Training loss: 3.6473. R^2: 0.4842.\n",
      "INFO:root:Epoch 5,000. Training loss: 3.2746. R^2: 0.5369.\n",
      "INFO:root:Epoch 5,100. Training loss: 3.3433. R^2: 0.5272.\n",
      "INFO:root:Epoch 5,200. Training loss: 3.2780. R^2: 0.5364.\n",
      "INFO:root:Epoch 5,300. Training loss: 3.5923. R^2: 0.4920.\n",
      "INFO:root:Epoch 5,400. Training loss: 3.1286. R^2: 0.5575.\n",
      "INFO:root:Epoch 5,500. Training loss: 3.5394. R^2: 0.4994.\n",
      "INFO:root:Epoch 5,600. Training loss: 3.1275. R^2: 0.5577.\n",
      "INFO:root:Epoch 5,700. Training loss: 3.3035. R^2: 0.5328.\n",
      "INFO:root:Epoch 5,800. Training loss: 3.1265. R^2: 0.5578.\n",
      "INFO:root:Epoch 5,900. Training loss: 3.1707. R^2: 0.5516.\n",
      "INFO:root:Epoch 6,000. Training loss: 3.2037. R^2: 0.5469.\n",
      "INFO:root:Epoch 6,100. Training loss: 3.4895. R^2: 0.5065.\n",
      "INFO:root:Epoch 6,200. Training loss: 3.1844. R^2: 0.5496.\n",
      "INFO:root:Epoch 6,300. Training loss: 3.4925. R^2: 0.5061.\n",
      "INFO:root:Epoch 6,400. Training loss: 3.2095. R^2: 0.5461.\n",
      "INFO:root:Epoch 6,500. Training loss: 3.2650. R^2: 0.5382.\n",
      "INFO:root:Epoch 6,600. Training loss: 3.2012. R^2: 0.5473.\n",
      "INFO:root:Epoch 6,700. Training loss: 3.2669. R^2: 0.5380.\n",
      "INFO:root:Epoch 6,800. Training loss: 3.4788. R^2: 0.5080.\n",
      "INFO:root:Epoch 6,900. Training loss: 3.2729. R^2: 0.5371.\n",
      "INFO:root:Epoch 7,000. Training loss: 3.3871. R^2: 0.5210.\n",
      "INFO:root:Epoch 7,100. Training loss: 3.4467. R^2: 0.5125.\n",
      "INFO:root:Epoch 7,200. Training loss: 3.1753. R^2: 0.5509.\n",
      "INFO:root:Epoch 7,300. Training loss: 3.1975. R^2: 0.5478.\n",
      "INFO:root:Epoch 7,400. Training loss: 3.5114. R^2: 0.5034.\n",
      "INFO:root:Epoch 7,500. Training loss: 3.2388. R^2: 0.5419.\n",
      "INFO:root:Epoch 7,600. Training loss: 3.1802. R^2: 0.5502.\n",
      "INFO:root:Epoch 7,700. Training loss: 3.3891. R^2: 0.5207.\n",
      "INFO:root:Epoch 7,800. Training loss: 3.1216. R^2: 0.5585.\n",
      "INFO:root:Epoch 7,900. Training loss: 3.2697. R^2: 0.5376.\n",
      "INFO:root:Epoch 8,000. Training loss: 3.1837. R^2: 0.5497.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/score_modeling.py:98\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m var_y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvar(y)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     periodic_logging(i, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. R^2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mloss_value\u001b[38;5;241m/\u001b[39mvar_y\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, v\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    101\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:70\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun_wrapper(\u001b[38;5;28;01mFalse\u001b[39;00m, args, kwargs)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:59\u001b[0m, in \u001b[0;36m_JitWrapper._fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached\u001b[38;5;241m.\u001b[39mlower(dynamic, static)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     dynamic_out, static_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combine(dynamic_out, static_out\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/module.py:285\u001b[0m, in \u001b[0;36mModule._tree_unflatten\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    278\u001b[0m             static_field_values\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(dynamic_field_values), (\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_names),\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_values),\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, aux, dynamic_field_values):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    288\u001b[0m     dynamic_field_names, static_field_names, static_field_values \u001b[38;5;241m=\u001b[39m aux\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ba26a52-61ae-4d1f-a0b6-21f65481b0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Test loss 3.742. R^2: 0.483.\n"
     ]
    }
   ],
   "source": [
    "loss_test = model_trainer.model.loss(x_test, y_test)\n",
    "var_y = jnp.var(y_test)\n",
    "logging.info(f'Test loss {loss_test:.3f}. R^2: {1-loss_test/var_y:.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1346a4-5787-4a9f-88c8-672cd19c2918",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8159094-38ee-4072-b271-f2d1daee87d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = LocalTransformerEncoderModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "901fb37f-875c-436f-9a23-b1f40ad49b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2.5000381], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78cfb572-92b6-4da5-897d-dffed123daa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(11.390394, dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.loss(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb172406-5d47-4bcf-8b37-54825ac379a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_trainer2 = ModelTrainer(model2, epochs=100, optimizer=optax.sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "017fa8cf-f3f3-46f3-ba7d-c2f02d8cd46d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0. Training loss: 11.3904. R^2: -0.6109.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_trainer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/score_modeling.py:98\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m var_y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvar(y)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     periodic_logging(i, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. R^2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mloss_value\u001b[38;5;241m/\u001b[39mvar_y\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, v\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m    101\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:70\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun_wrapper(\u001b[38;5;28;01mFalse\u001b[39;00m, args, kwargs)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/jit.py:59\u001b[0m, in \u001b[0;36m_JitWrapper._fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached\u001b[38;5;241m.\u001b[39mlower(dynamic, static)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     dynamic_out, static_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combine(dynamic_out, static_out\u001b[38;5;241m.\u001b[39mvalue)\n",
      "File \u001b[0;32m~/Research/Adaptive Genome/code/venv/lib/python3.9/site-packages/equinox/module.py:285\u001b[0m, in \u001b[0;36mModule._tree_unflatten\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    278\u001b[0m             static_field_values\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(dynamic_field_values), (\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(dynamic_field_names),\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_names),\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(static_field_values),\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, aux, dynamic_field_values):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    288\u001b[0m     dynamic_field_names, static_field_names, static_field_values \u001b[38;5;241m=\u001b[39m aux\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer2.train(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gene_venv",
   "language": "python",
   "name": "gene_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
